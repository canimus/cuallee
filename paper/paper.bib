@article{10.1145/3603707,
author = {Fadlallah, Hadi and Kilany, Rima and Dhayne, Houssein and El Haddad, Rami and Haque, Rafiqul and Taher, Yehia and Jaber, Ali},
year = {2023},
month = {06},
pages = {},
title = {Context-aware Big Data Quality Assessment: A Scoping Review},
volume = {15},
journal = {Journal of Data and Information Quality},
doi = {10.1145/3603707}
}

@article{10.1145/3603706,
author = {Fadlallah, Hadi and Kilany, Rima and Dhayne, Houssein and El Haddad, Rami and Haque, Rafiqul and Taher, Yehia and Jaber, Ali},
year = {2023},
month = {06},
pages = {},
title = {BIGQA: Declarative Big Data Quality Assessment},
volume = {15},
journal = {Journal of Data and Information Quality},
doi = {10.1145/3603706}
}

@inproceedings{10.1145/3580305.3599776,
author = {Tu, Dezhan and He, Yeye and Cui, Weiwei and Ge, Song and Zhang, Haidong and Han, Shi and Zhang, Dongmei and Chaudhuri, Surajit},
title = {Auto-Validate by-History: Auto-Program Data Quality Constraints to Validate Recurring Data Pipelines},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599776},
doi = {10.1145/3580305.3599776},
abstract = {Data pipelines are widely employed in modern enterprises to power a variety of Machine-Learning (ML) and Business-Intelligence (BI) applications. Crucially, these pipelines are recurring (e.g., daily or hourly) in production settings to keep data updated so that ML models can be re-trained regularly, and BI dashboards refreshed frequently. However, data quality (DQ) issues can often creep into recurring pipelines because of upstream schema and data drift over time. As modern enterprises operate thousands of recurring pipelines, today data engineers have to spend substantial efforts to manually monitor and resolve DQ issues, as part of their DataOps and MLOps practices.Given the high human cost of managing large-scale pipeline operations, it is imperative that we can automate as much as possible. In this work, we propose Auto-Validate-by-History (AVH) that can automatically detect DQ issues in recurring pipelines, leveraging rich statistics from historical executions. We formalize this as an optimization problem, and develop constant-factor approximation algorithms with provable precision guarantees. Extensive evaluations using 2000 production data pipelines at Microsoft demonstrate the effectiveness and efficiency of AVH.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4991–5003},
numpages = {13},
keywords = {data drift, data histories, data pipelines, data quality, data validation, dataops, mlops, statistical constraints},
location = {<conf-loc>, <city>Long Beach</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
series = {KDD '23}
}


@article{10.14778/3229863.3229867,
author = {Schelter, Sebastian and Lange, Dustin and Schmidt, Philipp and Celikel, Meltem and Biessmann, Felix and Grafberger, Andreas},
title = {Automating large-scale data quality verification},
year = {2018},
issue_date = {August 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3229863.3229867},
doi = {10.14778/3229863.3229867},
abstract = {Modern companies and institutions rely on data to guide every single business process and decision. Missing or incorrect information seriously compromises any decision process downstream. Therefore, a crucial, but tedious task for everyone involved in data processing is to verify the quality of their data. We present a system for automating the verification of data quality at scale, which meets the requirements of production use cases. Our system provides a declarative API, which combines common quality constraints with user-defined validation code, and thereby enables 'unit tests' for data. We efficiently execute the resulting constraint validation workload by translating it to aggregation queries on Apache Spark. Our platform supports the incremental validation of data quality on growing datasets, and leverages machine learning, e.g., for enhancing constraint suggestions, for estimating the 'predictability' of a column, and for detecting anomalies in historic data quality time series. We discuss our design decisions, describe the resulting system architecture, and present an experimental evaluation on various datasets.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {1781–1794},
numpages = {14}
}


@inproceedings{10.1145/3529190.3529222,
author = {Pleimling, Xavier and Shah, Vedant and Lourentzou, Ismini},
title = {[Data] Quality Lies In The Eyes Of The Beholder},
year = {2022},
isbn = {9781450396318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3529190.3529222},
doi = {10.1145/3529190.3529222},
abstract = {As large-scale machine learning models become more prevalent in assistive and pervasive technologies, the research community has started examining limitations and challenges that arise from training data, e.g., fairness, bias, and interpretability issues. To this end, data-centric approaches are increasingly prevailing over time, showing that high-quality data is a critical component in many applications. Several studies explore methods to define and improve data quality, however, no uniform definition exists. In this work, we present an empirical analysis of the multifaceted problem of evaluating data quality. Our work aims at identifying data quality challenges that are most commonly observed by data users and practitioners. Inspired by the need for generally applicable methods, we select a representative set of quality indicators, that covers a broad spectrum of issues, and investigate the utility of these indicators on a broad range of datasets through inter-annotator agreement analysis. Our work provides insights and presents open challenges in designing improved data life cycles.},
booktitle = {Proceedings of the 15th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {118–124},
numpages = {7},
keywords = {data annotation, data quality, data quality metrics, data utility, datasets, duplicate data, incomplete data, inconsistent data, incorrect data, user survey},
location = {Corfu, Greece},
series = {PETRA '22}
}

@inproceedings{10.1145/2723372.2742797,
author = {Armbrust, Michael and Xin, Reynold S. and Lian, Cheng and Huai, Yin and Liu, Davies and Bradley, Joseph K. and Meng, Xiangrui and Kaftan, Tomer and Franklin, Michael J. and Ghodsi, Ali and Zaharia, Matei},
title = {Spark SQL: Relational Data Processing in Spark},
year = {2015},
isbn = {9781450327589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723372.2742797},
doi = {10.1145/2723372.2742797},
abstract = {Spark SQL is a new module in Apache Spark that integrates relational processing with Spark's functional programming API. Built on our experience with Shark, Spark SQL lets Spark programmers leverage the benefits of relational processing (e.g. declarative queries and optimized storage), and lets SQL users call complex analytics libraries in Spark (e.g. machine learning). Compared to previous systems, Spark SQL makes two main additions. First, it offers much tighter integration between relational and procedural processing, through a declarative DataFrame API that integrates with procedural Spark code. Second, it includes a highly extensible optimizer, Catalyst, built using features of the Scala programming language, that makes it easy to add composable rules, control code generation, and define extension points. Using Catalyst, we have built a variety of features (e.g. schema inference for JSON, machine learning types, and query federation to external databases) tailored for the complex needs of modern data analysis. We see Spark SQL as an evolution of both SQL-on-Spark and of Spark itself, offering richer APIs and optimizations while keeping the benefits of the Spark programming model.},
booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
pages = {1383–1394},
numpages = {12},
keywords = {data warehouse, databases, hadoop, machine learning, spark},
location = {Melbourne, Victoria, Australia},
series = {SIGMOD '15}
}

@inproceedings{10.1145/2872427.2883029,
author = {Pezoa, Felipe and Reutter, Juan and Suarez, Fernando and Ugarte, Martin and Vrgoč, Domagoj},
year = {2016},
month = {04},
pages = {263-273},
title = {Foundations of JSON Schema},
doi = {10.1145/2872427.2883029}
}

@article{10.3389/fdata.2020.564115,
  title={Toward Data Lakes as Central Building Blocks for Data Management and Analysis},
  author={Dumke, André R. and Parchmann, Andreas and Schmid, Stefan and Hauswirth, Manfred},
  journal={Frontiers in Big Data},
  volume={3},
  pages={564115},
  year={2020},
  publisher={Frontiers},
  doi={10.3389/fdata.2020.564115}
}

@misc{oreilly2023technology,
  title = {Technology Trends for 2023},
  author = {{O'Reilly Media}},
  year = {2023},
  url = {https://www.oreilly.com/radar/technology-trends-for-2023/},
  note = {Accessed: 2024-05-18}
}

@misc{cuallee_performance_tests,
  author       = {Herminio Vazquez},
  title        = {cuallee: Performance Tests},
  year         = {2024},
  url          = {https://github.com/canimus/cuallee/tree/main/test/performance},
  note         = {Accessed: 2024-05-19}
}

@misc{nyc_tlc_trip_record_data,
  author       = {{New York City Taxi and Limousine Commission}},
  title        = {TLC Trip Record Data},
  year         = {2024},
  url          = {https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page},
  note         = {Accessed: 2024-05-19}
}

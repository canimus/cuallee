{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Welcome to <code>cuallee</code> and thanks for using this amazing framework. None of this work could have been possible without the inspiration of <code>pydeequ</code>. So, thanks to the AWS folks for putting the research work together, and the references so that we could build on the shoulders of giants.</p> <p>This <code>pure-python</code> implementation of unit tests for your data, will help you define validations for your data using <code>3</code> concepts described below:</p>"},{"location":"#entities","title":"Entities","text":"<p>To better understand <code>cuallee</code> you will need to get familiar with the following 3 concepts: <code>Check</code>, <code>Rule</code> and <code>ComputeInstruction</code>.</p> Entity Icon Description <code>Check</code> Use it to define a group of validations on a <code>dataframe</code> and report them as <code>WARNING</code> or <code>ERROR</code>. You can chain as many rules into a <code>check</code>, internally <code>cuallee</code> will make sure the same rule is not executed twice. <code>Rule</code> A <code>rule</code> represents the predicate you want to test on a <code>single</code> or <code>multiple</code> columns in a dataframe. A rule as a 4 attributes <code>method</code>: name of the predicate, <code>column</code>: the column in the dataframe, <code>value</code>: the value to compare against and <code>coverage</code>: the percentage of positive predicate necessary to set the status of the check to <code>PASS</code>. <code>Control</code> Currently only supported in <code>pyspark</code> it allows to run pre-fabricated checks that target all columns in a dataframe. Controls help a user to run validation faster, without having to add individual rules for each column on a dataframe. For example <code>Control.completeness</code> creates a Check, and then adds <code>is_complete</code> rules to each column of the dataframe <p>In principle, the only interface you need to be familiar with is the <code>Check</code> as it is through this <code>object</code> that you can chain your validations and then directly through the <code>validate</code> method, execute validations on any <code>DataFrame</code>.</p>"},{"location":"#process","title":"Process","text":"<p><code>cuallee</code> is designed to rapidly develop quality rules for your data.The process consists in the following  steps: <pre><code>graph LR\n\n  A[Create Check] -.-&gt; B[Add Rules];\n  B[Add Rules] -.-&gt; C[Load Data];\n  C[Load Data] -.-&gt; D[Validate DataFrame];\n</code></pre></p> <ol> <li>Create Check: Consists in calling the <code>check = Check()</code> constructor to initiate a validation</li> <li>Add_Rules: consists in calling any of the rules available in the check, providing a <code>column</code> and when required a expected <code>value</code>. For example: <code>check.is_unique(id)</code></li> <li>Load Data: Is the process of creating a dataframe normally by loading data from your data sources, by convention in the docs we refer to dataframes as <code>df</code>. For example in <code>pandas</code> <code>df = pd.read_csv(\"data.csv\")</code></li> <li>Validate DataFrame: Consists in running <code>check.validate(df)</code></li> </ol>"},{"location":"#history","title":"History","text":"<p>Why did we create a software that offers functionality similar to <code>pydeequ</code>, <code>great-expectations</code>, and <code>soda-core</code>? While these tools are inspiring and have lowered the barrier for better data quality in the complex ecosystem of data platforms, they are primarily geared towards enterprise, collaborative, and licensed-supported software.</p> <p>Cuallee's operational model, from day one, aimed to be a transparent, reliable, and robust solution for large-scale data sources and team profiles. It focuses on portability and ease of use. Differing from the <code>low-code</code> movement that foster authoring data quality checks without coding experience or through configuration formats like YAML or proprietary meta-languages.</p> <p>Cuallee championed the idea of maintaining a code-centric approach to quality definitions, focusing on areas where data defects are statistically more likely to appear. This includes the logistics of moving data and the transformation phase, where business logic is needed to process original sources. This approach aligns with the concept of safeguarding data through its life-cycle via unit tests, as originally proposed by the deequ framework.</p> <p>There were three main reasons for cuallee becoming a standalone solution rather than just a contribution to the pydeequ framework:</p> <ul> <li>Scala development: Cuallee is written entirely in Python, which benefits from a larger development ecosystem, especially considering Python's dominance in the data ecosystem.</li> <li>Computation model: The architecture of initializing a pydeequ session encountered friction during the implementation of quality rules, influencing memory footprint and requiring additional jar files for use in PySpark.</li> <li>Extensibility to other data structures: Cuallee addresses the widely adopted workflow for data experimentation, where teams often start their journeys in <code>notebooks</code> or local environments before transitioning to packaged software releases, subject to more stringent criteria like vulnerability management, release management, quality control, telemetry, etc. Plus, the transition to <code>out-of-memory</code> frameworks like PySpark for distributed execution.</li> </ul> <p>In summary, <code>cuallee</code> provides a Python-centric, transparent, and robust solution for data quality testing, particularly suited for teams operating in hybrid environments or undergoing technology migrations.</p>"},{"location":"catalogue/","title":"Catalogue","text":"<p>The following table contains the list of all available checks in <code>cuallee</code>:</p>"},{"location":"catalogue/#checks","title":"Checks","text":"Check Description DataType <code>is_complete</code> Zero <code>nulls</code> agnostic <code>is_empty</code> All <code>nulls</code> agnostic <code>is_unique</code> Zero <code>duplicates</code> agnostic <code>is_primary_key</code> Zero <code>duplicates</code> agnostic <code>are_complete</code> Zero <code>nulls</code> on group of columns agnostic <code>are_unique</code> Composite primary key check agnostic <code>is_composite_key</code> Zero duplicates on multiple columns agnostic <code>is_greater_than</code> <code>col &gt; x</code> numeric <code>is_positive</code> <code>col &gt; 0</code> numeric <code>is_negative</code> <code>col &lt; 0</code> numeric <code>is_greater_or_equal_than</code> <code>col &gt;= x</code> numeric <code>is_less_than</code> <code>col &lt; x</code> numeric <code>is_less_or_equal_than</code> <code>col &lt;= x</code> numeric <code>is_equal_than</code> <code>col == x</code> numeric <code>is_contained_in</code> <code>col in [a, b, c, ...]</code> agnostic <code>is_in</code> Alias of <code>is_contained_in</code> agnostic <code>not_contained_in</code> <code>col not in [a, b, c, ...]</code> agnostic <code>not_in</code> Alias of <code>not_contained_in</code> agnostic <code>is_between</code> <code>a &lt;= col &lt;= b</code> numeric, date <code>has_pattern</code> Matching a pattern defined as a <code>regex</code> string <code>is_legit</code> String not null &amp; not empty <code>^\\S$</code> string <code>has_min</code> <code>min(col) == x</code> numeric <code>has_max</code> <code>max(col) == x</code> numeric <code>has_std</code> <code>\u03c3(col) == x</code> numeric <code>has_mean</code> <code>\u03bc(col) == x</code> numeric <code>has_sum</code> <code>\u03a3(col) == x</code> numeric <code>has_percentile</code> <code>%(col) == x</code> numeric <code>has_cardinality</code> <code>count(distinct(col)) == x</code> agnostic <code>has_infogain</code> <code>count(distinct(col)) &gt; 1</code> agnostic <code>has_max_by</code> A utilitary predicate for <code>max(col_a) == x for max(col_b)</code> agnostic <code>has_min_by</code> A utilitary predicate for <code>min(col_a) == x for min(col_b)</code> agnostic <code>has_correlation</code> Finds correlation between <code>0..1</code> on <code>corr(col_a, col_b)</code> numeric <code>has_entropy</code> Calculates the entropy of a column <code>entropy(col) == x</code> for classification problems numeric <code>is_inside_interquartile_range</code> Verifies column values reside inside limits of interquartile range <code>Q1 &lt;= col &lt;= Q3</code> used on anomalies. numeric <code>is_in_millions</code> <code>col &gt;= 1e6</code> numeric <code>is_in_billions</code> <code>col &gt;= 1e9</code> numeric <code>is_t_minus_1</code> For date fields confirms 1 day ago <code>t-1</code> date <code>is_t_minus_2</code> For date fields confirms 2 days ago <code>t-2</code> date <code>is_t_minus_3</code> For date fields confirms 3 days ago <code>t-3</code> date <code>is_t_minus_n</code> For date fields confirms n days ago <code>t-n</code> date <code>is_today</code> For date fields confirms day is current date <code>t-0</code> date <code>is_yesterday</code> For date fields confirms 1 day ago <code>t-1</code> date <code>is_on_weekday</code> For date fields confirms day is between <code>Mon-Fri</code> date <code>is_on_weekend</code> For date fields confirms day is between <code>Sat-Sun</code> date <code>is_on_monday</code> For date fields confirms day is <code>Mon</code> date <code>is_on_tuesday</code> For date fields confirms day is <code>Tue</code> date <code>is_on_wednesday</code> For date fields confirms day is <code>Wed</code> date <code>is_on_thursday</code> For date fields confirms day is <code>Thu</code> date <code>is_on_friday</code> For date fields confirms day is <code>Fri</code> date <code>is_on_saturday</code> For date fields confirms day is <code>Sat</code> date <code>is_on_sunday</code> For date fields confirms day is <code>Sun</code> date <code>is_on_schedule</code> For date fields confirms time windows i.e. <code>9:00 - 17:00</code> timestamp <code>is_daily</code> Can verify daily continuity on date fields by default. <code>[2,3,4,5,6]</code> which represents <code>Mon-Fri</code> in PySpark. However new schedules can be used for custom date continuity date <code>has_workflow</code> Adjacency matrix validation on <code>3-column</code> graph, based on <code>group</code>, <code>event</code>, <code>order</code> columns. agnostic <code>satisfies</code> An open <code>SQL expression</code> builder to construct custom checks agnostic <code>validate</code> The ultimate transformation of a check with a <code>dataframe</code> input for validation agnostic"},{"location":"catalogue/#controls","title":"Controls","text":"<p>Currently available only for <code>pyspark</code> and <code>pandas</code> dataframes.</p> Check Description DataType <code>completeness</code> Zero <code>nulls</code> agnostic <code>information</code> Zero nulls <code>and</code> cardinality &gt; 1 agnostic <code>intelligence</code> Zero nulls, zero empty strings and cardinality &gt; 1 agnostic <code>percentage_fill</code> <code>% rows</code> not empty agnostic <code>percentage_empty</code> <code>% rows</code> empty agnostic <p>Demo</p> <pre><code>import pandas as pd\nfrom cuallee import Control\ndf = pd.DataFrame({\"X\":[1,2,3], \"Y\": [10,20,30]})\n# Checks all columns in dataframe for using is_complete check\nControl.completeness(df)\n</code></pre>"},{"location":"catalogue/#iso","title":"ISO","text":"<p>A new module has been incorporated in <code>cuallee&gt;=0.4.0</code> which allows the verification of International Standard Organization columns in data frames. Simply access the <code>check.iso</code> interface to add the set of checks as shown below.</p> Check Description DataType <code>iso_4217</code> currency compliant <code>ccy</code> string <code>iso_3166</code> country compliant <code>country</code> string <p>Demo</p> <pre><code>df = spark.createDataFrame([[1, \"USD\"], [2, \"MXN\"], [3, \"CAD\"], [4, \"EUR\"], [5, \"CHF\"]], [\"id\", \"ccy\"])\ncheck = Check(CheckLevel.WARNING, \"ISO Compliant\")\ncheck.iso.iso_4217(\"ccy\")\ncheck.validate(df).show()\n+---+-------------------+-------------+-------+------+---------------+--------------------+----+----------+---------+--------------+------+\n| id|          timestamp|        check|  level|column|           rule|               value|rows|violations|pass_rate|pass_threshold|status|\n+---+-------------------+-------------+-------+------+---------------+--------------------+----+----------+---------+--------------+------+\n|  1|2023-05-14 18:28:02|ISO Compliant|WARNING|   ccy|is_contained_in|{'BHD', 'CRC', 'M...|   5|       0.0|      1.0|           1.0|  PASS|\n+---+-------------------+-------------+-------+------+---------------+--------------------+----+----------+---------+--------------+------+\n</code></pre>"},{"location":"dependencies/","title":"Dependencies","text":"<p>It relies has only  dependencies that are automatically installed with the package:</p> <ul> <li><code>toolz</code> for functional programming adoption</li> <li><code>requests</code> for downloading ISO standard required by <code>check.iso</code> interface.</li> </ul>"},{"location":"dependencies/#metrics","title":"Metrics","text":"<p>As a lightweight and near-zero-dependency framework <code>cuallee</code> excels by its simplicity.</p> <ul> <li><code>4.5k</code> lines of code </li> <li><code>&lt;10</code> on code complexity for all validations </li> <li><code>0</code> lines of code duplicated </li> </ul> Module Lines Complexity <code>pyspark</code> <code>773</code> <code>7</code> <code>pandas</code> <code>343</code> <code>0</code> <code>polars</code> <code>450</code> <code>2</code> <code>duckdb</code> <code>232</code> <code>4</code> <code>snowpark</code> <code>817</code> <code>3</code> <code>bigquery</code> <code>275</code> <code>4</code> <p>Reference: scc</p>"},{"location":"installation/","title":"Installation","text":"<p><code>cuallee</code> is developed with a <code>functional</code> programming style. Classes are only defined for  compatibility and ease the migration process from <code>pydeeque</code>.</p> <p>For better performance it requires <code>pyspark&gt;=3.3.0</code> and the <code>Observation</code> API.</p>"},{"location":"installation/#requirements","title":"Requirements","text":"<p><code>cuallee</code> is available independently of your operative system, you can run <code>cuallee</code> on:</p> <ul> <li><code>Linux</code> </li> <li><code>MacOS</code> </li> <li><code>Windows</code> </li> </ul> <p>The binaries in the python <code>wheel</code> are built universally so as far as you have a python interpreter with the minimum version <code>&gt;=3.8</code> you are all set.</p>"},{"location":"installation/#using-pip","title":"Using pip","text":"<pre><code># Latest\npip install cuallee\n</code></pre>"},{"location":"installation/#external-frameworks","title":"External frameworks","text":"<p>If you are operating in an environment and your frameworks are already installed, then there is no need or requirement to install them separately. If you are starting from scratch and you choose for <code>cuallee</code> to install the compatible or supported versions of the data frameworks, you could choose from the following <code>optional-dependencies</code> available in <code>cuallee</code>.</p> <p><pre><code># For Pyspark\npip install cuallee[pyspark]\n\n# For Spark Connect\npip install cuallee[pyspark_connect]\n\n# For Snowflake/Snowpark\npip install cuallee[snowpark]\n\n# For DuckDb\npip install cuallee[duckdb]\n\n# For Polars\npip install cuallee[polars]\n\n# For Snowpark\npip install cuallee[snowpark]\n</code></pre> Alternatively, you can have your own versions of the frameworks installed separately in your environment and <code>cuallee</code> simply will rely in the version installed, considering it meets its minimum requirements and compatibility.</p>"},{"location":"bigquery/","title":"BigQuery","text":"<p>In order to follow this examples, make sure your installation is all set for <code>bigquery</code></p> <p>Install</p> <pre><code>pip install cuallee\npip install cuallee[bigquery]\n</code></pre>"},{"location":"bigquery/#pre-requisites","title":"Pre-Requisites","text":"<p>You will need a Google Cloud account active, with the BigQuery API enabled to proceed with this examples. Once your account is enabled with BigQuery, you will have to export a <code>service account</code> credential file in <code>json</code> format.</p> <p><code>cuallee</code> will read the environment variable <code>GOOGLE_APPLICATION_CREDENTIALS</code> expecting the name of the file that contains your <code>service account credentials</code></p> <p>Cost Associated</p> <p>Be aware that running <code>cuallee</code> checks in <code>bigquery</code> incurs into cloud costs.</p> <p>The process inside <code>cuallee</code> to handle the credentials is as follows:</p> <p>Credentials Handling</p> <pre><code>import os\nfrom google.cloud import bigquery\n\ncredentials = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\nclient = bigquery.Client(project=\"GOOGLE_CLOUD_PROJECT_IDENTIFIER\", credentials=credentials)\n</code></pre>"},{"location":"bigquery/#is_complete","title":"is_complete","text":"<p>It validates the completeness attribute of a data set. It confirms that a column does not contain <code>null</code> values   .</p> is_complete  PASS FAIL THRESHOLD <p>In this example, we validate that the column <code>id</code> does not have any missing values.</p> <pre><code>from google.cloud import bigquery\nfrom cuallee import Check\n\n# Public dataset in BigQuery\ndf = bigquery.dataset.Table(\"bigquery-public-data.chicago_taxi_trips.taxi_trips\")\ncheck = Check()\ncheck.is_complete(\"taxi_id\")\n\n# Validate\ncheck.validate(df)\n</code></pre> <p> output:</p> <pre><code>            timestamp          check    level   column         rule value       rows  violations  pass_rate  pass_threshold status\nid\n1   2024-05-18 21:24:15  cuallee.check  WARNING  taxi_id  is_complete   N/A  102589284           0        1.0             1.0   PASS\n</code></pre> <p>In this example, we intentionally place 2 <code>null</code> values in the dataframe and that produces a <code>FAIL</code> check as result.</p> <pre><code>from google.cloud import bigquery\nfrom cuallee import Check\n\n# Public dataset in BigQuery\ndf = bigquery.dataset.Table(\"bigquery-public-data.chicago_taxi_trips.taxi_trips\")\ncheck = Check()\ncheck.is_complete(\"trip_end_timestamp\")\n\n# Validate\ncheck.validate(df)\n</code></pre> <p> output:</p> <pre><code>            timestamp          check    level              column         rule value       rows  violations  pass_rate  pass_threshold status\nid\n1   2024-05-18 21:24:15  cuallee.check  WARNING  trip_end_timestamp  is_complete   N/A  102589284        1589   0.999985             1.0   FAIL\n</code></pre> <p>In this example, we validate reuse the data frame with empty values from the previous example, however we set our tolerance via the <code>pct</code> parameter on the rule <code>is_complete</code> to <code>0.6</code>. Producing now a <code>PASS</code> result on the check, regardless of the <code>2</code> present <code>null</code> values.</p> <pre><code>from google.cloud import bigquery\nfrom cuallee import Check\n\n# Public dataset in BigQuery\ndf = bigquery.dataset.Table(\"bigquery-public-data.chicago_taxi_trips.taxi_trips\")\ncheck = Check()\ncheck.is_complete(\"trip_end_timestamp\", pct=0.9)\n\n# Validate\ncheck.validate(df)\n</code></pre> <p> output:</p> <pre><code>            timestamp          check    level              column         rule value       rows  violations  pass_rate  pass_threshold status\nid\n1   2024-05-18 21:24:15  cuallee.check  WARNING  trip_end_timestamp  is_complete   N/A  102589284        1589   0.999985             0.9   PASS\n</code></pre>"},{"location":"daft/","title":"Daft","text":"<p>In order to follow this examples, make sure your installation is all set for <code>daft</code></p> <p>Install</p> <pre><code>pip install cuallee\npip install cuallee[daft]\n</code></pre>"},{"location":"daft/#is_complete","title":"is_complete","text":"<p>It validates the completeness attribute of a data set. It confirms that a column does not contain <code>null</code> values.</p> is_complete  PASS FAIL THRESHOLD <p>In this example, we validate that the column <code>id</code> does not have any missing values.</p> <pre><code>import daft\nimport numpy as np\nfrom cuallee import Check, CheckLevel\n\ndf = daft.from_pydict({\"id\": np.arange(10)})\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(df)\n</code></pre> <p> output:</p> <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 check             \u2506 column \u2506 id    \u2506 level   \u2506 pass_rate \u2506 pass_threshold \u2506 rows  \u2506 rule        \u2506 status \u2506 timestamp           \u2506 value \u2506 violations \u2502\n\u2502 ---               \u2506 ---    \u2506 ---   \u2506 ---     \u2506 ---       \u2506 ---            \u2506 ---   \u2506 ---         \u2506 ---    \u2506 ---                 \u2506 ---   \u2506 ---        \u2502\n\u2502 Utf8              \u2506 Utf8   \u2506 Int64 \u2506 Utf8    \u2506 Float64   \u2506 Float64        \u2506 Int64 \u2506 Utf8        \u2506 Utf8   \u2506 Utf8                \u2506 Utf8  \u2506 Int64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 CompletePredicate \u2506 id     \u2506 1     \u2506 WARNING \u2506 1         \u2506 1              \u2506 10    \u2506 is_complete \u2506 PASS   \u2506 2024-03-26 18:55:43 \u2506 N/A   \u2506 0          \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>In this example, we intentionally place 2 <code>null</code> values in the dataframe and that produces a <code>FAIL</code> check as result.</p> <pre><code>import daft\nimport numpy as np\nfrom cuallee import Check, CheckLevel\n\ndf = daft.from_pydict({\"id\": [1,2,3,None,None]})\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(df)\n</code></pre> <p> output:</p> <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 check             \u2506 column \u2506 id    \u2506 level   \u2506 pass_rate \u2506 pass_threshold \u2506 rows  \u2506 rule        \u2506 status \u2506 timestamp           \u2506 value \u2506 violations \u2502\n\u2502 ---               \u2506 ---    \u2506 ---   \u2506 ---     \u2506 ---       \u2506 ---            \u2506 ---   \u2506 ---         \u2506 ---    \u2506 ---                 \u2506 ---   \u2506 ---        \u2502\n\u2502 Utf8              \u2506 Utf8   \u2506 Int64 \u2506 Utf8    \u2506 Float64   \u2506 Float64        \u2506 Int64 \u2506 Utf8        \u2506 Utf8   \u2506 Utf8                \u2506 Utf8  \u2506 Int64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 CompletePredicate \u2506 id     \u2506 1     \u2506 WARNING \u2506 0.6       \u2506 1              \u2506 5     \u2506 is_complete \u2506 FAIL   \u2506 2024-05-18 21:24:15 \u2506 N/A   \u2506 2          \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>In this example, we validate reuse the data frame with empty values from the previous example, however we set our tolerance via the <code>pct</code> parameter on the rule <code>is_complete</code> to <code>0.6</code>. Producing now a <code>PASS</code> result on the check, regardless of the <code>2</code> present <code>null</code> values.</p> <pre><code>import daft\nimport numpy as np\nfrom cuallee import Check, CheckLevel\n\ndf = daft.from_pydict({\"id\": [1,2,3,None,None]})\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\", pct=.6)\n\n# Validate\ncheck.validate(df)\n</code></pre> <p> output:</p> <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 check             \u2506 column \u2506 id    \u2506 level   \u2506 pass_rate \u2506 pass_threshold \u2506 rows  \u2506 rule        \u2506 status \u2506 timestamp           \u2506 value \u2506 violations \u2502\n\u2502 ---               \u2506 ---    \u2506 ---   \u2506 ---     \u2506 ---       \u2506 ---            \u2506 ---   \u2506 ---         \u2506 ---    \u2506 ---                 \u2506 ---   \u2506 ---        \u2502\n\u2502 Utf8              \u2506 Utf8   \u2506 Int64 \u2506 Utf8    \u2506 Float64   \u2506 Float64        \u2506 Int64 \u2506 Utf8        \u2506 Utf8   \u2506 Utf8                \u2506 Utf8  \u2506 Int64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 CompletePredicate \u2506 id     \u2506 1     \u2506 WARNING \u2506 0.6       \u2506 0.6            \u2506 5     \u2506 is_complete \u2506 PASS   \u2506 2024-05-18 21:24:15 \u2506 N/A   \u2506 2          \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"duckdb/","title":"DuckDB","text":"<p>In order to follow this examples, make sure your installation is all set for <code>duckdb</code></p> <p>Install</p> <pre><code>pip install cuallee\npip install cuallee[duckdb]\n</code></pre> <p>The example illustrated in this section, uses <code>pandas</code> to create a test data structure, as opposed <code>DML</code> in <code>duckdb</code> to create a <code>table</code> or <code>view</code> to conduct the demonstration. <code>duckdb</code> uses a <code>pyarrow</code> to access the <code>pandas</code> dataframes in memory, and therefore is capable to interpret a <code>pandas</code> dataframe as a <code>virtual table</code> from which it can run queries. The name given to the <code>virtual table</code> is the variable name in the case of the majority of the examples this is: <code>df</code> or alternatively <code>df2</code>.</p> <p>You can find more information here.</p>"},{"location":"duckdb/#data-structures","title":"Data Structures","text":""},{"location":"duckdb/#duckdbpyconnection","title":"<code>DuckDBPyConnection</code>","text":"<p><code>duckdb</code> is a rapid changing framework with a relatively fast release cadence. That means that keeping up to date with their releases is challenging. For example in version <code>0.10.0</code> the project introduced a PySpark API that allow users to interact with a DuckDB database with a very similar API as that of Spark. However, parity of the APIs is not <code>100%</code> and in practice, the most reliable API for <code>duckdb</code> is always the <code>SQL</code> interface. For that reason, in <code>cuallee</code> we decided to use that interface to <code>duckdb</code> as opposed to the one closest to the <code>dataframe</code>.</p> <p>What this means, is that <code>cuallee</code> uses the following data type to interact with the data:</p> <p>Supported</p> <pre><code>import duckdb\nconn = duckdb.connect(\":memory:\")\ntype(conn)\nduckdb.duckdb.DuckDBPyConnection\n</code></pre>"},{"location":"duckdb/#duckdbpyrelation","title":"<code>DuckDBPyRelation</code>","text":"<p><code>cuallee</code> does not support the relational API as of version <code>0.10.3</code>. Implenting it, will depend on the parity of functionality with the native <code>SQL</code> API in DuckDb. Currently not all the operations supported in the native <code>SQL</code> API of duckdb are available through the relational API, and therefore it has limitations when trying to match their siblings for instance with PySpark or Pandas.</p> <p>Not Supported</p> <pre><code>import duckdb\nconn = duckdb.read_parquet(\"data.parquet\")\ntype(conn)\nduckdb.duckdb.DuckDBPyRelation\n</code></pre>"},{"location":"duckdb/#checks","title":"Checks","text":""},{"location":"duckdb/#is_complete","title":"is_complete","text":"<p>It validates the completeness attribute of a data set. It confirms that a column does not contain <code>null</code> values   .</p> is_complete  PASS FAIL THRESHOLD <p>In this example, we validate that the column <code>id</code> does not have any missing values.</p> <pre><code>import pandas as pd\nimport duckdb\nfrom cuallee import Check\n\nconn = duckdb.connect(\":memory:\")\ndf = pd.DataFrame({\"id\" : [1,2,3,4,5]})\ncheck = Check(table_name=\"df\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(conn)\n</code></pre> <p> output:</p> <pre><code>id            timestamp          check    level column         rule value  rows  violations  pass_rate  pass_threshold status\n 1  2024-05-18 16:22:53  cuallee.check  WARNING     id  is_complete   N/A     5           0        1.0             1.0   PASS\n</code></pre> <p>In this example, we intentionally place 2 <code>null</code> values in the dataframe and that produces a <code>FAIL</code> check as result.</p> <pre><code>import pandas as pd\nimport duckdb\nfrom cuallee import Check\n\nconn = duckdb.connect(\":memory:\")\ndf = pd.DataFrame({\"id\" : [1,2,3,None, None]})\ncheck = Check(table_name=\"df\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(conn)\n</code></pre> <p> output:</p> <pre><code>id            timestamp          check    level column         rule value  rows  violations  pass_rate  pass_threshold status\n 1  2024-05-18 16:33:55  cuallee.check  WARNING     id  is_complete   N/A     5           2        0.6             1.0   FAIL\n</code></pre> <p>In this example, we validate reuse the data frame with empty values from the previous example, however we set our tolerance via the <code>pct</code> parameter on the rule <code>is_complete</code> to <code>0.6</code>. Producing now a <code>PASS</code> result on the check, regardless of the <code>2</code> present <code>null</code> values.</p> <pre><code>import pandas as pd\nimport duckdb\nfrom cuallee import Check\n\nconn = duckdb.connect(\":memory:\")\ndf = pd.DataFrame({\"id\" : [1,2,3,None, None]})\ncheck = Check(table_name=\"df\")\ncheck.is_complete(\"id\", pct=0.6)\n\n# Validate\ncheck.validate(conn)\n</code></pre> <p> output:</p> <pre><code>id            timestamp          check    level column         rule value  rows  violations  pass_rate  pass_threshold status\n 1  2024-05-18 16:33:55  cuallee.check  WARNING     id  is_complete   N/A     5           2        0.6             0.6   PASS\n</code></pre>"},{"location":"frameworks/","title":"Dataframes","text":""},{"location":"frameworks/#what-are-dataframes","title":"What are DataFrames?","text":"<p>To begin your journey with <code>cuallee</code> is important to denote what is the data structure used for data validation.</p> DataFrame <p>Is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns) in Python, provided by the pandas library. It is one of the most commonly used data structures for data manipulation and analysis in Python.</p>"},{"location":"frameworks/#key-features-of-a-dataframe","title":"Key Features of a DataFrame:","text":"<ol> <li> <p>Two-Dimensional: It represents data in a table-like format with rows and columns, similar to a spreadsheet or SQL table.</p> </li> <li> <p>Labeled Axes: Each row and column in a DataFrame has a label. Columns are labeled with column names, and rows are labeled with an index.</p> </li> <li> <p>Heterogeneous Data: Different columns can contain different types of data (e.g., integers, floats, strings, etc.).</p> </li> <li> <p>Size-Mutable: The size of the DataFrame can be changed; you can add or drop rows and columns as needed.</p> </li> <li> <p>Powerful Data Alignment: DataFrames allow for complex operations on data sets, including handling missing data, merging/joining different data sets, and reshaping data.</p> </li> </ol>"},{"location":"frameworks/#creating-a-dataframe","title":"Creating a DataFrame","text":"<p>You can create a DataFrame in several ways, such as from a dictionary of lists, lists of dictionaries, or reading data from a file (e.g., CSV, Excel).</p>"},{"location":"frameworks/#example-1-creating-a-dataframe-from-a-dictionary-of-lists","title":"Example 1: Creating a DataFrame from a Dictionary of Lists","text":"<pre><code>import pandas as pd\n\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [25, 30, 35],\n    'City': ['New York', 'San Francisco', 'Los Angeles']\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n</code></pre>"},{"location":"frameworks/#example-2-creating-a-dataframe-from-a-list-of-dictionaries","title":"Example 2: Creating a DataFrame from a List of Dictionaries","text":"<pre><code>import pandas as pd\n\ndata = [\n    {'Name': 'Alice', 'Age': 25, 'City': 'New York'},\n    {'Name': 'Bob', 'Age': 30, 'City': 'San Francisco'},\n    {'Name': 'Charlie', 'Age': 35, 'City': 'Los Angeles'}\n]\n\ndf = pd.DataFrame(data)\nprint(df)\n</code></pre>"},{"location":"frameworks/#example-3-reading-a-dataframe-from-a-csv-file","title":"Example 3: Reading a DataFrame from a CSV File","text":"<pre><code>import pandas as pd\n\ndf = pd.read_csv('data.csv')\nprint(df)\n</code></pre>"},{"location":"frameworks/#basic-operations-on-dataframes","title":"Basic Operations on DataFrames","text":""},{"location":"frameworks/#accessing-data","title":"Accessing Data","text":"<ul> <li>Selecting a Column: <code>df['ColumnName']</code> or <code>df.ColumnName</code></li> <li>Selecting Multiple Columns: <code>df[['Column1', 'Column2']]</code></li> <li>Selecting Rows by Index: <code>df.loc[index]</code> or <code>df.iloc[index]</code> for integer-location based indexing</li> </ul>"},{"location":"frameworks/#adding-and-dropping-columns","title":"Adding and Dropping Columns","text":"<ul> <li>Adding a Column: <code>df['NewColumn'] = value</code></li> <li>Dropping a Column: <code>df.drop('ColumnName', axis=1, inplace=True)</code></li> </ul>"},{"location":"frameworks/#filtering-data","title":"Filtering Data","text":"<ul> <li>Filtering Rows Based on Condition: <code>df[df['ColumnName'] &gt; value]</code></li> </ul>"},{"location":"frameworks/#example-basic-dataframe-operations","title":"Example: Basic DataFrame Operations","text":"<pre><code>import pandas as pd\n\n# Creating the DataFrame\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [25, 30, 35],\n    'City': ['New York', 'San Francisco', 'Los Angeles']\n}\n\ndf = pd.DataFrame(data)\n\n# Selecting a column\nprint(df['Name'])\n\n# Adding a new column\ndf['Salary'] = [70000, 80000, 90000]\n\n# Dropping a column\ndf.drop('City', axis=1, inplace=True)\n\n# Filtering rows where Age is greater than 28\nfiltered_df = df[df['Age'] &gt; 28]\n\nprint(filtered_df)\n</code></pre>"},{"location":"frameworks/#advanced-features","title":"Advanced Features","text":"<ul> <li>Group By: Allows you to group data and perform aggregate functions.</li> <li>Merge/Join: Combining multiple DataFrames based on a common key.</li> <li>Pivot Tables: Creating pivot tables for summarizing data.</li> <li>Handling Missing Data: Functions to detect, remove, or fill missing values.</li> </ul> <p>DataFrames are a powerful and flexible data structure for data analysis, and mastering their use can greatly enhance your ability to work with data in Python.</p>"},{"location":"module/check/","title":"Check","text":"Source code in <code>cuallee/__init__.py</code> <pre><code>class Check:\n    def __init__(\n        self,\n        level: Union[CheckLevel, int] = 0,\n        name: str = \"cuallee.check\",\n        *,\n        execution_date: datetime = datetime.now(timezone.utc),\n        table_name: str = None,\n        session: Any = None,\n    ):\n        \"\"\"\n        A container of data quality rules.\n\n        Args:\n            level (CheckLevel): [0-1] value to describe if its a WARNING or ERROR check\n            name (str): Normally the name of the dataset being verified, or a name for this check\n            execution_date (date): An automatically generated timestamp of the check in UTC\n            table_name (str): When using databases matches the table name of the source\n            session (Session): When operating in Session enabled environments like Databricks or Snowflake\n\n        \"\"\"\n        self._rule: Dict[str, Rule] = {}\n        self.compute_engine: ModuleType\n\n        if isinstance(level, int):\n            # When the user is lazy and wants to do WARN=0, or ERR=1\n            level = CheckLevel(level)\n\n        self.level = level\n        self.name = name\n        self.date = execution_date\n        self.rows = -1\n        self.config: Dict[str, str] = {}\n        self.table_name = table_name\n        self.dtype = \"cuallee.dataframe\"\n        try:\n            from .iso.checks import ISO\n            from .bio.checks import BioChecks\n\n            self.iso = ISO(self)\n            self.bio = BioChecks(self)\n        except (ModuleNotFoundError, ImportError) as err:\n            logger.error(f\"Dependency modules missing: {str(err)}\")\n        self.session = session\n\n    def __repr__(self):\n        standard = (\n            f\"Check(level:{self.level}, description:{self.name}, rules:{self.sum})\"\n        )\n        if self.table_name:\n            standard += f\" / table:{self.table_name}\"\n        return standard\n\n    @property\n    def sum(self):\n        \"\"\"Total number of rules in Check\"\"\"\n        return len(self._rule.keys())\n\n    @property\n    def rules(self):\n        \"\"\"Returns all rules defined for check\"\"\"\n        return list(self._rule.values())\n\n    @property\n    def keys(self):\n        \"\"\"Returns blake2s unique identifiers of rules\"\"\"\n        return list(self._rule.keys())\n\n    @property\n    def empty(self):\n        \"\"\"True when no rules are added in the check\"\"\"\n        return len(self.rules) == 0\n\n    def _remove_rule_generic(self, key: str):\n        \"\"\"\n        Remove a key from rules and compute dictionaries\n\n        Args:\n            key (str): the blake2s key of the rule\n        \"\"\"\n        if key in self._rule:\n            self._rule.pop(key)\n\n    def add_rule(self, method: str, *arg, **kwargs):\n        \"\"\"\n        Add a new rule to the Check class.\n\n        Args:\n            method (str): Check name\n            arg (list): Parameters of the Rule\n            kwars (dict): Dictionary of options for the Rule\n        \"\"\"\n        return operator.methodcaller(method, *arg, **kwargs)(self)\n\n    def delete_rule_by_key(self, keys: Union[str, List[str]]):\n        \"\"\"\n        Delete rules from check based on keys.\n\n        Args:\n            keys (List[str]): a single or list of keys to remove from the check\n        \"\"\"\n        if isinstance(keys, str):\n            keys = [keys]\n\n        [self._remove_rule_generic(key) for key in keys]\n        return self\n\n    def delete_rule_by_attribute(\n        self,\n        rule_attribute: Literal[\"method\", \"column\", \"coverage\"],\n        values: Union[List[str], List[float]],\n    ):\n        \"\"\"\n        Delete rule based on method(s) or column name(s) or coverage value(s).\n\n        Args:\n            rule_attribute (str): Finds a rule with by: method, column or coverage\n            values (List[str]): Deletes a rule that matches the rule_attribute equal to the value in this parameter\n        \"\"\"\n        if not isinstance(values, List):\n            values = [values]\n\n        _filter = lambda x: operator.attrgetter(rule_attribute)(x) in values\n\n        [\n            self._remove_rule_generic(key)\n            for key in valfilter(_filter, self._rule).keys()\n        ]\n        return self\n\n    def adjust_rule_coverage(self, rule_index: int, rule_coverage: float):\n        \"\"\"\n        Adjust the ratio predicate/rows for a rule.\n        It is intended to lower or increase tolerance without having to rewrite the entire check\n\n        Args:\n            rule_index (int): The position of the rule in the check list\n            rule_coverage (float): New value between [0..1] for tolerance\n\n        \"\"\"\n        target_rule = self.rules[rule_index]\n        old_key = target_rule.key\n        target_rule = self._rule.pop(old_key)\n        target_rule.coverage = rule_coverage\n        target_rule &gt;&gt; self._rule\n        return self\n\n    def is_complete(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validation for non-null values in column\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n\n        \"\"\"\n        Rule(\"is_complete\", column, \"N/A\", CheckDataType.AGNOSTIC, pct) &gt;&gt; self._rule\n        return self\n\n    def is_empty(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validation for null values in column\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n\n        \"\"\"\n        Rule(\"is_empty\", column, \"N/A\", CheckDataType.AGNOSTIC, pct) &gt;&gt; self._rule\n        return self\n\n    def are_complete(self, column: Union[List[str], Tuple[str, str]], pct: float = 1.0):\n        \"\"\"\n        Validation for non-null values in a group of columns\n\n        Args:\n            column (List[str]): A tuple or list of column names in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"are_complete\", column, \"N/A\", CheckDataType.AGNOSTIC, pct) &gt;&gt; self._rule\n        return self\n\n    def is_unique(\n        self,\n        column: str,\n        pct: float = 1.0,\n        approximate: bool = False,\n        ignore_nulls: bool = False,\n    ):\n        \"\"\"\n        Validation for unique values in column\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n            approximate (bool): A flag to speed up computation using an approximation through maximum relative std. dev.\n            ignore_nulls (bool): Run drop nulls before counting\n        \"\"\"\n        (\n            Rule(\n                \"is_unique\",\n                column,\n                \"N/A\",\n                CheckDataType.AGNOSTIC,\n                pct,\n                options={\"approximate\": approximate, \"ignore_nulls\": ignore_nulls},\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def is_primary_key(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validation for unique values in column\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        (\n            Rule(\n                \"is_unique\",\n                column,\n                \"N/A\",\n                CheckDataType.AGNOSTIC,\n                pct,\n                options={\"name\": \"is_primary_key\"},\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def are_unique(self, column: Union[List[str], Tuple[str, str]], pct: float = 1.0):\n        \"\"\"\n        Validation for unique values in a group of columns\n\n        Args:\n            column (List[str]): A tuple or list of column names in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"are_unique\", column, \"N/A\", CheckDataType.AGNOSTIC, pct) &gt;&gt; self._rule\n        return self\n\n    def is_composite_key(\n        self, column: Union[List[str], Tuple[str, str]], pct: float = 1.0\n    ):\n        \"\"\"\n        Validation for unique values in a group of columns\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        (\n            Rule(\n                \"are_unique\",\n                column,\n                \"N/A\",\n                CheckDataType.AGNOSTIC,\n                pct,\n                options={\"name\": \"is_composite_key\"},\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def is_greater_than(self, column: str, value: float, pct: float = 1.0):\n        \"\"\"\n        Validation for numeric greater than value\n\n        Args:\n            column (str): Column name in dataframe\n            value (number): The condition for the column to match\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"is_greater_than\", column, value, CheckDataType.NUMERIC, pct) &gt;&gt; self._rule\n        return self\n\n    def is_positive(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validation for numeric greater than zero\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        return self.is_greater_than(column, 0, pct)\n\n    def is_greater_or_equal_than(self, column: str, value: float, pct: float = 1.0):\n        \"\"\"\n        Validation for numeric greater or equal than value\n\n        Args:\n            column (str): Column name in dataframe\n            value (number): The condition for the column to match\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        (\n            Rule(\"is_greater_or_equal_than\", column, value, CheckDataType.NUMERIC, pct)\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def is_in_millions(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validates that a column has values greater than 1M (1e6)\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        return self.is_greater_or_equal_than(column, 1e6, pct)\n\n    def is_in_billions(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validates that a column has values greater than 1B (1e9)\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        return self.is_greater_or_equal_than(column, 1e9, pct)\n\n    def is_less_than(self, column: str, value: float, pct: float = 1.0):\n        \"\"\"\n        Validation for numeric less than value\n\n        Args:\n            column (str): Column name in dataframe\n            value (number): The condition for the column to match\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"is_less_than\", column, value, CheckDataType.NUMERIC, pct) &gt;&gt; self._rule\n        return self\n\n    def is_negative(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validation for numeric less than zero\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        return self.is_less_than(column, 0, pct)\n\n    def is_less_or_equal_than(self, column: str, value: float, pct: float = 1.0):\n        \"\"\"\n        Validation for numeric less or equal than value\n\n        Args:\n            column (str): Column name in dataframe\n            value (number): The condition for the column to match\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        (\n            Rule(\"is_less_or_equal_than\", column, value, CheckDataType.NUMERIC, pct)\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def is_equal_than(self, column: str, value: float, pct: float = 1.0):\n        \"\"\"\n        Validation for numeric column equal than value\n\n        Args:\n            column (str): Column name in dataframe\n            value (number): The condition for the column to match\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"is_equal_than\", column, value, CheckDataType.NUMERIC, pct) &gt;&gt; self._rule\n        return self\n\n    def has_pattern(\n        self, column: str, value: str, pct: float = 1.0, options: Dict[str, str] = {}\n    ):\n        \"\"\"\n        Validation for string type column matching regex expression\n\n        Args:\n            column (str): Column name in dataframe\n            value (regex): A regular expression used to  match values in the `column`\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        (\n            Rule(\n                \"has_pattern\", column, value, CheckDataType.STRING, pct, options=options\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def is_legit(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validation for string columns giving wrong signal about completeness due to empty strings.\n\n        Useful for reading CSV files and preventing empty strings being reported as valid records.\n        This is an `alias` implementation of the `has_pattern` rule using `not black space` as the pattern\n        Which validates the presence of non-empty characters between the begining and end of a string.\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        (\n            Rule(\n                \"has_pattern\",\n                column,\n                r\"^\\S+$\",\n                CheckDataType.STRING,\n                pct,\n                options={\"name\": \"is_legit\"},\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def has_min(self, column: str, value: float):\n        \"\"\"\n        Validation of a column's minimum value\n\n        Args:\n            column (str): Column name in dataframe\n            value (number): The condition for the column to match\n        \"\"\"\n        Rule(\"has_min\", column, value, CheckDataType.NUMERIC) &gt;&gt; self._rule\n        return self\n\n    def has_max(self, column: str, value: float):\n        \"\"\"\n        Validation of a column's maximum value\n\n        Args:\n            column (str): Column name in dataframe\n            value (number): The condition for the column to match\n        \"\"\"\n        Rule(\"has_max\", column, value, CheckDataType.NUMERIC) &gt;&gt; self._rule\n        return self\n\n    def has_std(self, column: str, value: float):\n        \"\"\"\n        Validation of a column's standard deviation\n\n        Args:\n            column (str): Column name in dataframe\n            value (number): The condition for the column to match\n        \"\"\"\n        Rule(\"has_std\", column, value, CheckDataType.NUMERIC) &gt;&gt; self._rule\n        return self\n\n    def has_mean(self, column: str, value: float):\n        \"\"\"\n        Validation of a column's average/mean\n\n        Args:\n            column (str): Column name in dataframe\n            value (number): The condition for the column to match\n        \"\"\"\n        Rule(\"has_mean\", column, value, CheckDataType.NUMERIC) &gt;&gt; self._rule\n        return self\n\n    def has_sum(self, column: str, value: float):\n        \"\"\"\n        Validation of a sum of all values of a column\n\n        Args:\n            column (str): Column name in dataframe\n            value (number): The condition for the column to match\n        \"\"\"\n        Rule(\"has_sum\", column, value, CheckDataType.NUMERIC) &gt;&gt; self._rule\n        return self\n\n    def is_between(self, column: str, value: Tuple[Any], pct: float = 1.0):\n        \"\"\"\n        Validation of a column between a range\n\n        Args:\n            column (str): Column name in dataframe\n            value (List[str,number,date]): The condition for the column to match\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"is_between\", column, value, CheckDataType.AGNOSTIC, pct) &gt;&gt; self._rule\n        return self\n\n    def not_contained_in(\n        self,\n        column: str,\n        value: Union[List, Tuple],\n        pct: float = 1.0,\n    ):\n        \"\"\"\n        Validation of column value not in set of given values\n\n        Args:\n            column (str): Column name in dataframe\n            value (List[str,number,date]): The condition for the column to match\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        (\n            Rule(\"not_contained_in\", column, value, CheckDataType.AGNOSTIC, pct)\n            &gt;&gt; self._rule\n        )\n\n        return self\n\n    def not_in(self, column: str, value: Tuple[str, int, float], pct: float = 1.0):\n        \"\"\"\n        Validation of column value not in set of given values\n\n        Args:\n            column (str): Column name in dataframe\n            value (List[str,number,date]): The condition for the column to match\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        return self.not_contained_in(column, value, pct)\n\n    def is_contained_in(\n        self,\n        column: str,\n        value: Union[List, Tuple],\n        pct: float = 1.0,\n        options: Dict[str, str] = {},\n    ):\n        \"\"\"\n        Validation of column value in set of given values\n\n        Args:\n            column (str): Column name in dataframe\n            value (List[str,number,date]): The condition for the column to match\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n\n        (\n            Rule(\n                \"is_contained_in\",\n                column,\n                value,\n                CheckDataType.AGNOSTIC,\n                pct,\n                options=options,\n            )\n            &gt;&gt; self._rule\n        )\n\n        return self\n\n    def is_in(self, column: str, value: Tuple[str, int, float], pct: float = 1.0):\n        \"\"\"\n        Vaildation of column value in set of given values\n\n        Args:\n            column (str): Column name in dataframe\n            value (List[str,number,date]): The condition for the column to match\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        return self.is_contained_in(column, value, pct, options={\"name\": \"is_in\"})\n\n    def is_t_minus_n(\n        self,\n        column: str,\n        value: int,\n        pct: float = 1.0,\n        options: Dict[str, str] = {\"name\": \"is_t_minus_n\"},\n    ):\n        \"\"\"\n        Validate that date is `n` days before the current date\n\n        Args:\n            column (str): Column name in dataframe\n            value (List[str,number,date]): The number of days before the current date\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        yesterday = datetime.utcnow() - timedelta(days=value)\n        return self.is_contained_in(\n            column, tuple([yesterday.strftime(\"%Y-%m-%d\")]), pct, options=options\n        )\n\n    def is_t_minus_1(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validate that date is yesterday\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        return self.is_t_minus_n(column, 1, pct, options={\"name\": \"is_t_minus_1\"})\n\n    def is_t_minus_2(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validate that date is 2 days ago\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        return self.is_t_minus_n(column, 2, pct, options={\"name\": \"is_t_minus_2\"})\n\n    def is_t_minus_3(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validate that date is 3 days ago\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        return self.is_t_minus_n(column, 3, pct, options={\"name\": \"is_t_minus_3\"})\n\n    def is_yesterday(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validate that date is yesterday\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        return self.is_t_minus_n(column, 1, pct, options={\"name\": \"is_yesterday\"})\n\n    def is_today(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validate that date is today\n\n        Args:\n            column (str): Column name in dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        return self.is_t_minus_n(column, 0, pct, options={\"name\": \"is_today\"})\n\n    def has_percentile(\n        self, column: str, value: float, percentile: float, precision: int = 10000\n    ):\n        \"\"\"\n        Validation of a column percentile value using approximation\n\n        Args:\n            column (str): Column name in dataframe\n            value (List[str,number,date]): The condition for the column to match\n            percentile (float): Value between [0,1] i.e. `0.5` for median\n            precision (float): The precision to calculate percentiles\n\n        \"\"\"\n        (\n            Rule(\n                \"has_percentile\",\n                column,\n                value,\n                CheckDataType.NUMERIC,\n                options=[\n                    tuple([\"percentile\", percentile]),\n                    tuple([\"precision\", precision]),\n                ],\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def is_inside_interquartile_range(\n        self, column: str, value: List[float] = [0.25, 0.75], pct: float = 1.0\n    ):\n        \"\"\"\n        Validates a number resides inside the quartile(1) and quartile(3) of the range of values\n\n        Args:\n            column (str): Column name in dataframe\n            value (List[number]): A number between 0 and 1 demarking the quartile\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        (\n            Rule(\n                \"is_inside_interquartile_range\",\n                column,\n                value,\n                CheckDataType.NUMERIC,\n                pct,\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def has_max_by(\n        self, column_source: str, column_target: str, value: Union[float, str]\n    ):\n        \"\"\"\n        Validation the correspondance of a column value based on another column maximum\n\n        Args:\n            column_source (str): Column used to obtain the row with the max value\n            column_target (str): Column used to verify the matching value\n            value (str,number): The value to match against\n        \"\"\"\n        (\n            Rule(\n                \"has_max_by\",\n                [column_source, column_target],\n                value,\n                CheckDataType.DUO,\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def has_min_by(\n        self, column_source: str, column_target: str, value: Union[float, str]\n    ):\n        \"\"\"\n        Validation the correspondence of a column value based on another column minimum\n\n        Args:\n            column_source (str): Column used to obtain the row with the min value\n            column_target (str): Column used to verify the matching value\n            value (str,number): The value to match against\n        \"\"\"\n        (\n            Rule(\n                \"has_min_by\",\n                [column_source, column_target],\n                value,\n                CheckDataType.DUO,\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def has_correlation(self, column_left: str, column_right: str, value: float):\n        \"\"\"\n        Validates the correlation in a range of [0..1] between 2 columns\n\n        Args:\n            column_left (str): Column name in dataframe\n            column_right (str): Column name in dataframe\n            value (float): Value to match the correlation\n        \"\"\"\n        (\n            Rule(\n                \"has_correlation\",\n                [column_left, column_right],\n                value,\n                CheckDataType.NUMERIC,\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def satisfies(\n        self,\n        column: str,\n        predicate: str,\n        pct: float = 1.0,\n        options: Dict[str, str] = {},\n    ):\n        \"\"\"\n        Validation of a column satisfying a SQL-like predicate\n\n        Args:\n            column (str): Column name in the dataframe\n            predicate (str): A predicate written in SQL-like syntax\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        (\n            Rule(\n                \"satisfies\",\n                column,\n                predicate,\n                CheckDataType.AGNOSTIC,\n                pct,\n                options=options,\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def has_cardinality(self, column: str, value: int):\n        \"\"\"\n        Validates the number of distinct values in a column\n\n        Args:\n            column (str): Column name in the dataframe\n            value (int): The number of expected distinct values on a column\n        \"\"\"\n        Rule(\"has_cardinality\", column, value, CheckDataType.AGNOSTIC) &gt;&gt; self._rule\n        return self\n\n    def has_infogain(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validate cardinality &gt; 1.\n        Particularly useful when validating categorical data for Machine Learning\n\n        Args:\n            column (str): Column name in the dataframe\n            pct (float): The threshold percentage required to pass\n\n        \"\"\"\n        (\n            Rule(\n                method=\"has_infogain\",\n                column=column,\n                value=\"N/A\",\n                data_type=CheckDataType.AGNOSTIC,\n                coverage=pct,\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def has_entropy(self, column: str, value: float, tolerance: float = 0.01):\n        \"\"\"\n        Validation for entropy calculation on continuous variables/features on `log2`.\n        Useful in Machine Learning classifications to test imbalanced datasets with low entropy.\n\n        Args:\n            column (str): Column name in the dataframe\n            value (float): The expected entropy value\n            tolerance (float): The tolerance/precision used when comparing the actual and expected value\n\n        Examples:\n\n        \"\"\"\n        (\n            Rule(\n                \"has_entropy\",\n                column,\n                value,\n                CheckDataType.AGNOSTIC,\n                options=[tuple([\"tolerance\", tolerance])],\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def is_on_weekday(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validates a datetime column is in a Mon-Fri time range\n\n        Args:\n            column (str): Column name in the dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"is_on_weekday\", column, \"Mon-Fri\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n        return self\n\n    def is_on_weekend(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validates a datetime column is in a Sat-Sun time range\n\n        Args:\n            column (str): Column name in the dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"is_on_weekend\", column, \"Sat-Sun\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n        return self\n\n    def is_on_monday(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validates a datetime column is on Monday\n\n        Args:\n            column (str): Column name in the dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"is_on_monday\", column, \"Mon\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n        return self\n\n    def is_on_tuesday(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validates a datetime column is on Tuesday\n\n        Args:\n            column (str): Column name in the dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"is_on_tuesday\", column, \"Tue\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n        return self\n\n    def is_on_wednesday(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validates a datetime column is on Wednesday\n\n        Args:\n            column (str): Column name in the dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"is_on_wednesday\", column, \"Wed\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n        return self\n\n    def is_on_thursday(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validates a datetime column is on Thursday\n\n        Args:\n            column (str): Column name in the dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"is_on_thursday\", column, \"Thu\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n        return self\n\n    def is_on_friday(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validates a datetime column is on Friday\n\n        Args:\n            column (str): Column name in the dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"is_on_friday\", column, \"Fri\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n        return self\n\n    def is_on_saturday(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validates a datetime column is on Saturday\n\n        Args:\n            column (str): Column name in the dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"is_on_saturday\", column, \"Sat\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n        return self\n\n    def is_on_sunday(self, column: str, pct: float = 1.0):\n        \"\"\"\n        Validates a datetime column is on Sunday\n\n        Args:\n            column (str): Column name in the dataframe\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        Rule(\"is_on_sunday\", column, \"Sun\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n        return self\n\n    def is_on_schedule(self, column: str, value: Tuple[Any], pct: float = 1.0):\n        \"\"\"\n        Validation of a datetime column between an hour interval\n\n        Args:\n            column (str): Column name in the dataframe\n            value (Tuple[int,int]): A tuple indicating a 24hr day interval. i.e. (9,17) for 9am to 5pm\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        (\n            Rule(\"is_on_schedule\", column, value, CheckDataType.TIMESTAMP, pct)\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def is_daily(\n        self, column: str, value: Union[None, List[int]] = None, pct: float = 1.0\n    ):\n        \"\"\"\n        Validates that there is no missing dates using only week days in the date/timestamp column.\n\n        An alternative day combination can be provided given that a user wants to validate only certain dates.\n        For example in PySpark to validate that time series are every Wednesday consecutively on a year\n        without any missing values, the value input should contain `[4]` as it represent the numeric\n        equivalence of the day of week Wednesday.\n\n        Args:\n            column (str): Column name in the dataframe\n            value (List[int]): A list of numbers describing the days of the week to consider. i.e. Pyspark uses [2, 3, 4, 5, 6] for Mon-Fri\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n        (Rule(\"is_daily\", column, value, CheckDataType.DATE, pct) &gt;&gt; self._rule)\n        return self\n\n    def has_workflow(\n        self,\n        column_group: str,\n        column_event: str,\n        column_order: str,\n        edges: List[Tuple[str]],\n        pct: float = 1.0,\n    ):\n        \"\"\"\n        Validates events in a group clause with order, followed a specific sequence. Similar to adjacency matrix validation.\n\n        Args:\n            column_group (str): The dataframe column used to group events\n            column_event (str): The state of the event within the group\n            column_order (List[date,number,str]): The order within the group, should be deterministic and without collisions.\n            edges (List[Tuple[str,str]]): The combinations of events expected in the data frame i.e `[(\"A\",\"B\"), (\"B\",\"C\")]`\n\n\n        ???+ example \"Example\"\n\n            Given the following fictitious dataset example:\n\n            | date       | ticket   | status      |\n            |------------|----------|-------------|\n            | 2024-01-01 | CASE-001 | New         |\n            | 2024-01-02 | CASE-001 | In Progress |\n            | 2024-01-03 | CASE-001 | Closed      |\n\n            You can validate that events for each ticket follow certain sequence by using:\n\n            ``` python\n            from cuallee import Check, CheckLevel\n            df = spark.createDataFrame(\n                 [\n                     [\"2024-01-01\", \"CASE-001\", \"New\"],\n                     [\"2024-01-02\", \"CASE-001\", \"In Progress\"],\n                     [\"2024-01-03\", \"CASE-001\", \"Closed\"],\n                 ],\n                 [\"date\", \"ticket\", \"status\"],\n             )\n\n\n            check = Check(CheckLevel.WARNING, \"WorkflowValidation\")\n            check.has_workflow(\n                column_group=\"ticket\",\n                column_event=\"status\",\n                column_order=\"date\",\n                edges=[(None, \"New\"),(\"New\", \"In Progress\"),(\"In Progress\",\"Closed\"), (\"Closed\", None)]\n            )\n\n            # Validate\n            check.validate(df).show(truncate=False)\n\n            # Result\n            +---+-------------------+------------------+-------+----------------------------+------------+------------------------------------------------------------------------------------+----+----------+---------+--------------+------+\n            |id |timestamp          |check             |level  |column                      |rule        |value                                                                               |rows|violations|pass_rate|pass_threshold|status|\n            +---+-------------------+------------------+-------+----------------------------+------------+------------------------------------------------------------------------------------+----+----------+---------+--------------+------+\n            |1  |2024-05-11 11:24:00|WorkflowValidation|WARNING|('ticket', 'status', 'date')|has_workflow|((None, 'New'), ('New', 'In Progress'), ('In Progress', 'Closed'), ('Closed', None))|3   |0         |1.0      |1.0           |PASS  |\n            +---+-------------------+------------------+-------+----------------------------+------------+------------------------------------------------------------------------------------+----+----------+---------+--------------+------+\n\n            ```\n\n        The check validates that:\n\n        - Nothing preceeds a `New` state\n        - `In Progress` follows the `New` event\n        - `Closed` follows the `In Progress` event\n        - Nothing follows after `Closed` state\n\n        \"\"\"\n        (\n            Rule(\n                \"has_workflow\",\n                [column_group, column_event, column_order],\n                edges,\n                CheckDataType.AGNOSTIC,\n                pct,\n            )\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def is_custom(\n        self,\n        column: Union[str, List[str]],\n        fn: Callable = None,\n        pct: float = 1.0,\n        options: Dict[str, str] = {},\n    ):\n        \"\"\"\n        Uses a user-defined function that receives the to-be-validated dataframe\n        and uses the last column of the transformed dataframe to summarize the check\n\n        Args:\n            column (str): Column(s) required for custom function\n            fn (Callable): A function that receives a dataframe as input and returns a dataframe with at least 1 column as result\n            pct (float): The threshold percentage required to pass\n        \"\"\"\n\n        (\n            Rule(\"is_custom\", column, fn, CheckDataType.AGNOSTIC, pct, options=options)\n            &gt;&gt; self._rule\n        )\n        return self\n\n    def validate(self, dataframe: Any, ok: bool = False):\n        \"\"\"\n        Compute all rules in this check for specific data frame\n\n        Args:\n            dataframe (Union[pyspark,snowpark,pandas,polars,duckdb,bigquery]): A dataframe object\n        \"\"\"\n\n        # Stop execution if the there is no rules in the check\n        assert not self.empty, \"Check is empty. Try adding some rules?\"\n\n        self.dtype = first(re.match(r\".*'(.*)'\", str(type(dataframe))).groups())\n        match self.dtype:\n            case self.dtype if \"pyspark\" in self.dtype:\n                self.compute_engine = importlib.import_module(\n                    \"cuallee.pyspark_validation\"\n                )\n            case self.dtype if \"pandas\" in self.dtype:\n                self.compute_engine = importlib.import_module(\n                    \"cuallee.pandas_validation\"\n                )\n            case self.dtype if \"snowpark\" in self.dtype:\n                self.compute_engine = importlib.import_module(\n                    \"cuallee.snowpark_validation\"\n                )\n            case self.dtype if \"polars\" in self.dtype:\n                self.compute_engine = importlib.import_module(\n                    \"cuallee.polars_validation\"\n                )\n            case self.dtype if \"duckdb\" in self.dtype:\n                self.compute_engine = importlib.import_module(\n                    \"cuallee.duckdb_validation\"\n                )\n            case self.dtype if \"bigquery\" in self.dtype:\n                self.compute_engine = importlib.import_module(\n                    \"cuallee.bigquery_validation\"\n                )\n            case self.dtype if \"daft\" in self.dtype:\n                self.compute_engine = importlib.import_module(\"cuallee.daft_validation\")\n            case _:\n                raise NotImplementedError(\n                    f\"{self.dtype} is not yet implemented in cuallee\"\n                )\n\n        assert self.compute_engine.validate_data_types(\n            self.rules, dataframe\n        ), \"Invalid data types between rules and dataframe\"\n\n        if ok:\n            result = self.compute_engine.ok(self, dataframe)\n        else:\n            result = self.compute_engine.summary(self, dataframe)\n        return result\n\n    def ok(self, dataframe: Any) -&gt; bool:\n        \"\"\"True when all checks passed\"\"\"\n        return self.validate(dataframe, ok=True)\n</code></pre>"},{"location":"module/check/#cuallee.Check.empty","title":"<code>empty</code>  <code>property</code>","text":"<p>True when no rules are added in the check</p>"},{"location":"module/check/#cuallee.Check.keys","title":"<code>keys</code>  <code>property</code>","text":"<p>Returns blake2s unique identifiers of rules</p>"},{"location":"module/check/#cuallee.Check.rules","title":"<code>rules</code>  <code>property</code>","text":"<p>Returns all rules defined for check</p>"},{"location":"module/check/#cuallee.Check.sum","title":"<code>sum</code>  <code>property</code>","text":"<p>Total number of rules in Check</p>"},{"location":"module/check/#cuallee.Check.__init__","title":"<code>__init__(level=0, name='cuallee.check', *, execution_date=datetime.now(timezone.utc), table_name=None, session=None)</code>","text":"<p>A container of data quality rules.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>CheckLevel</code> <p>[0-1] value to describe if its a WARNING or ERROR check</p> <code>0</code> <code>name</code> <code>str</code> <p>Normally the name of the dataset being verified, or a name for this check</p> <code>'cuallee.check'</code> <code>execution_date</code> <code>date</code> <p>An automatically generated timestamp of the check in UTC</p> <code>now(utc)</code> <code>table_name</code> <code>str</code> <p>When using databases matches the table name of the source</p> <code>None</code> <code>session</code> <code>Session</code> <p>When operating in Session enabled environments like Databricks or Snowflake</p> <code>None</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def __init__(\n    self,\n    level: Union[CheckLevel, int] = 0,\n    name: str = \"cuallee.check\",\n    *,\n    execution_date: datetime = datetime.now(timezone.utc),\n    table_name: str = None,\n    session: Any = None,\n):\n    \"\"\"\n    A container of data quality rules.\n\n    Args:\n        level (CheckLevel): [0-1] value to describe if its a WARNING or ERROR check\n        name (str): Normally the name of the dataset being verified, or a name for this check\n        execution_date (date): An automatically generated timestamp of the check in UTC\n        table_name (str): When using databases matches the table name of the source\n        session (Session): When operating in Session enabled environments like Databricks or Snowflake\n\n    \"\"\"\n    self._rule: Dict[str, Rule] = {}\n    self.compute_engine: ModuleType\n\n    if isinstance(level, int):\n        # When the user is lazy and wants to do WARN=0, or ERR=1\n        level = CheckLevel(level)\n\n    self.level = level\n    self.name = name\n    self.date = execution_date\n    self.rows = -1\n    self.config: Dict[str, str] = {}\n    self.table_name = table_name\n    self.dtype = \"cuallee.dataframe\"\n    try:\n        from .iso.checks import ISO\n        from .bio.checks import BioChecks\n\n        self.iso = ISO(self)\n        self.bio = BioChecks(self)\n    except (ModuleNotFoundError, ImportError) as err:\n        logger.error(f\"Dependency modules missing: {str(err)}\")\n    self.session = session\n</code></pre>"},{"location":"module/check/#cuallee.Check.add_rule","title":"<code>add_rule(method, *arg, **kwargs)</code>","text":"<p>Add a new rule to the Check class.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Check name</p> required <code>arg</code> <code>list</code> <p>Parameters of the Rule</p> <code>()</code> <code>kwars</code> <code>dict</code> <p>Dictionary of options for the Rule</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def add_rule(self, method: str, *arg, **kwargs):\n    \"\"\"\n    Add a new rule to the Check class.\n\n    Args:\n        method (str): Check name\n        arg (list): Parameters of the Rule\n        kwars (dict): Dictionary of options for the Rule\n    \"\"\"\n    return operator.methodcaller(method, *arg, **kwargs)(self)\n</code></pre>"},{"location":"module/check/#cuallee.Check.adjust_rule_coverage","title":"<code>adjust_rule_coverage(rule_index, rule_coverage)</code>","text":"<p>Adjust the ratio predicate/rows for a rule. It is intended to lower or increase tolerance without having to rewrite the entire check</p> <p>Parameters:</p> Name Type Description Default <code>rule_index</code> <code>int</code> <p>The position of the rule in the check list</p> required <code>rule_coverage</code> <code>float</code> <p>New value between [0..1] for tolerance</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def adjust_rule_coverage(self, rule_index: int, rule_coverage: float):\n    \"\"\"\n    Adjust the ratio predicate/rows for a rule.\n    It is intended to lower or increase tolerance without having to rewrite the entire check\n\n    Args:\n        rule_index (int): The position of the rule in the check list\n        rule_coverage (float): New value between [0..1] for tolerance\n\n    \"\"\"\n    target_rule = self.rules[rule_index]\n    old_key = target_rule.key\n    target_rule = self._rule.pop(old_key)\n    target_rule.coverage = rule_coverage\n    target_rule &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.are_complete","title":"<code>are_complete(column, pct=1.0)</code>","text":"<p>Validation for non-null values in a group of columns</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>List[str]</code> <p>A tuple or list of column names in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def are_complete(self, column: Union[List[str], Tuple[str, str]], pct: float = 1.0):\n    \"\"\"\n    Validation for non-null values in a group of columns\n\n    Args:\n        column (List[str]): A tuple or list of column names in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"are_complete\", column, \"N/A\", CheckDataType.AGNOSTIC, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.are_unique","title":"<code>are_unique(column, pct=1.0)</code>","text":"<p>Validation for unique values in a group of columns</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>List[str]</code> <p>A tuple or list of column names in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def are_unique(self, column: Union[List[str], Tuple[str, str]], pct: float = 1.0):\n    \"\"\"\n    Validation for unique values in a group of columns\n\n    Args:\n        column (List[str]): A tuple or list of column names in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"are_unique\", column, \"N/A\", CheckDataType.AGNOSTIC, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.delete_rule_by_attribute","title":"<code>delete_rule_by_attribute(rule_attribute, values)</code>","text":"<p>Delete rule based on method(s) or column name(s) or coverage value(s).</p> <p>Parameters:</p> Name Type Description Default <code>rule_attribute</code> <code>str</code> <p>Finds a rule with by: method, column or coverage</p> required <code>values</code> <code>List[str]</code> <p>Deletes a rule that matches the rule_attribute equal to the value in this parameter</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def delete_rule_by_attribute(\n    self,\n    rule_attribute: Literal[\"method\", \"column\", \"coverage\"],\n    values: Union[List[str], List[float]],\n):\n    \"\"\"\n    Delete rule based on method(s) or column name(s) or coverage value(s).\n\n    Args:\n        rule_attribute (str): Finds a rule with by: method, column or coverage\n        values (List[str]): Deletes a rule that matches the rule_attribute equal to the value in this parameter\n    \"\"\"\n    if not isinstance(values, List):\n        values = [values]\n\n    _filter = lambda x: operator.attrgetter(rule_attribute)(x) in values\n\n    [\n        self._remove_rule_generic(key)\n        for key in valfilter(_filter, self._rule).keys()\n    ]\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.delete_rule_by_key","title":"<code>delete_rule_by_key(keys)</code>","text":"<p>Delete rules from check based on keys.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>List[str]</code> <p>a single or list of keys to remove from the check</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def delete_rule_by_key(self, keys: Union[str, List[str]]):\n    \"\"\"\n    Delete rules from check based on keys.\n\n    Args:\n        keys (List[str]): a single or list of keys to remove from the check\n    \"\"\"\n    if isinstance(keys, str):\n        keys = [keys]\n\n    [self._remove_rule_generic(key) for key in keys]\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_cardinality","title":"<code>has_cardinality(column, value)</code>","text":"<p>Validates the number of distinct values in a column</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>value</code> <code>int</code> <p>The number of expected distinct values on a column</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def has_cardinality(self, column: str, value: int):\n    \"\"\"\n    Validates the number of distinct values in a column\n\n    Args:\n        column (str): Column name in the dataframe\n        value (int): The number of expected distinct values on a column\n    \"\"\"\n    Rule(\"has_cardinality\", column, value, CheckDataType.AGNOSTIC) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_correlation","title":"<code>has_correlation(column_left, column_right, value)</code>","text":"<p>Validates the correlation in a range of [0..1] between 2 columns</p> <p>Parameters:</p> Name Type Description Default <code>column_left</code> <code>str</code> <p>Column name in dataframe</p> required <code>column_right</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>float</code> <p>Value to match the correlation</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def has_correlation(self, column_left: str, column_right: str, value: float):\n    \"\"\"\n    Validates the correlation in a range of [0..1] between 2 columns\n\n    Args:\n        column_left (str): Column name in dataframe\n        column_right (str): Column name in dataframe\n        value (float): Value to match the correlation\n    \"\"\"\n    (\n        Rule(\n            \"has_correlation\",\n            [column_left, column_right],\n            value,\n            CheckDataType.NUMERIC,\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_entropy","title":"<code>has_entropy(column, value, tolerance=0.01)</code>","text":"<p>Validation for entropy calculation on continuous variables/features on <code>log2</code>. Useful in Machine Learning classifications to test imbalanced datasets with low entropy.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>value</code> <code>float</code> <p>The expected entropy value</p> required <code>tolerance</code> <code>float</code> <p>The tolerance/precision used when comparing the actual and expected value</p> <code>0.01</code> <p>Examples:</p> Source code in <code>cuallee/__init__.py</code> <pre><code>def has_entropy(self, column: str, value: float, tolerance: float = 0.01):\n    \"\"\"\n    Validation for entropy calculation on continuous variables/features on `log2`.\n    Useful in Machine Learning classifications to test imbalanced datasets with low entropy.\n\n    Args:\n        column (str): Column name in the dataframe\n        value (float): The expected entropy value\n        tolerance (float): The tolerance/precision used when comparing the actual and expected value\n\n    Examples:\n\n    \"\"\"\n    (\n        Rule(\n            \"has_entropy\",\n            column,\n            value,\n            CheckDataType.AGNOSTIC,\n            options=[tuple([\"tolerance\", tolerance])],\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_infogain","title":"<code>has_infogain(column, pct=1.0)</code>","text":"<p>Validate cardinality &gt; 1. Particularly useful when validating categorical data for Machine Learning</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def has_infogain(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validate cardinality &gt; 1.\n    Particularly useful when validating categorical data for Machine Learning\n\n    Args:\n        column (str): Column name in the dataframe\n        pct (float): The threshold percentage required to pass\n\n    \"\"\"\n    (\n        Rule(\n            method=\"has_infogain\",\n            column=column,\n            value=\"N/A\",\n            data_type=CheckDataType.AGNOSTIC,\n            coverage=pct,\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_max","title":"<code>has_max(column, value)</code>","text":"<p>Validation of a column's maximum value</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>number</code> <p>The condition for the column to match</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def has_max(self, column: str, value: float):\n    \"\"\"\n    Validation of a column's maximum value\n\n    Args:\n        column (str): Column name in dataframe\n        value (number): The condition for the column to match\n    \"\"\"\n    Rule(\"has_max\", column, value, CheckDataType.NUMERIC) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_max_by","title":"<code>has_max_by(column_source, column_target, value)</code>","text":"<p>Validation the correspondance of a column value based on another column maximum</p> <p>Parameters:</p> Name Type Description Default <code>column_source</code> <code>str</code> <p>Column used to obtain the row with the max value</p> required <code>column_target</code> <code>str</code> <p>Column used to verify the matching value</p> required <code>value</code> <code>(str, number)</code> <p>The value to match against</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def has_max_by(\n    self, column_source: str, column_target: str, value: Union[float, str]\n):\n    \"\"\"\n    Validation the correspondance of a column value based on another column maximum\n\n    Args:\n        column_source (str): Column used to obtain the row with the max value\n        column_target (str): Column used to verify the matching value\n        value (str,number): The value to match against\n    \"\"\"\n    (\n        Rule(\n            \"has_max_by\",\n            [column_source, column_target],\n            value,\n            CheckDataType.DUO,\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_mean","title":"<code>has_mean(column, value)</code>","text":"<p>Validation of a column's average/mean</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>number</code> <p>The condition for the column to match</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def has_mean(self, column: str, value: float):\n    \"\"\"\n    Validation of a column's average/mean\n\n    Args:\n        column (str): Column name in dataframe\n        value (number): The condition for the column to match\n    \"\"\"\n    Rule(\"has_mean\", column, value, CheckDataType.NUMERIC) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_min","title":"<code>has_min(column, value)</code>","text":"<p>Validation of a column's minimum value</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>number</code> <p>The condition for the column to match</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def has_min(self, column: str, value: float):\n    \"\"\"\n    Validation of a column's minimum value\n\n    Args:\n        column (str): Column name in dataframe\n        value (number): The condition for the column to match\n    \"\"\"\n    Rule(\"has_min\", column, value, CheckDataType.NUMERIC) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_min_by","title":"<code>has_min_by(column_source, column_target, value)</code>","text":"<p>Validation the correspondence of a column value based on another column minimum</p> <p>Parameters:</p> Name Type Description Default <code>column_source</code> <code>str</code> <p>Column used to obtain the row with the min value</p> required <code>column_target</code> <code>str</code> <p>Column used to verify the matching value</p> required <code>value</code> <code>(str, number)</code> <p>The value to match against</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def has_min_by(\n    self, column_source: str, column_target: str, value: Union[float, str]\n):\n    \"\"\"\n    Validation the correspondence of a column value based on another column minimum\n\n    Args:\n        column_source (str): Column used to obtain the row with the min value\n        column_target (str): Column used to verify the matching value\n        value (str,number): The value to match against\n    \"\"\"\n    (\n        Rule(\n            \"has_min_by\",\n            [column_source, column_target],\n            value,\n            CheckDataType.DUO,\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_pattern","title":"<code>has_pattern(column, value, pct=1.0, options={})</code>","text":"<p>Validation for string type column matching regex expression</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>regex</code> <p>A regular expression used to  match values in the <code>column</code></p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def has_pattern(\n    self, column: str, value: str, pct: float = 1.0, options: Dict[str, str] = {}\n):\n    \"\"\"\n    Validation for string type column matching regex expression\n\n    Args:\n        column (str): Column name in dataframe\n        value (regex): A regular expression used to  match values in the `column`\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    (\n        Rule(\n            \"has_pattern\", column, value, CheckDataType.STRING, pct, options=options\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_percentile","title":"<code>has_percentile(column, value, percentile, precision=10000)</code>","text":"<p>Validation of a column percentile value using approximation</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>List[str, number, date]</code> <p>The condition for the column to match</p> required <code>percentile</code> <code>float</code> <p>Value between [0,1] i.e. <code>0.5</code> for median</p> required <code>precision</code> <code>float</code> <p>The precision to calculate percentiles</p> <code>10000</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def has_percentile(\n    self, column: str, value: float, percentile: float, precision: int = 10000\n):\n    \"\"\"\n    Validation of a column percentile value using approximation\n\n    Args:\n        column (str): Column name in dataframe\n        value (List[str,number,date]): The condition for the column to match\n        percentile (float): Value between [0,1] i.e. `0.5` for median\n        precision (float): The precision to calculate percentiles\n\n    \"\"\"\n    (\n        Rule(\n            \"has_percentile\",\n            column,\n            value,\n            CheckDataType.NUMERIC,\n            options=[\n                tuple([\"percentile\", percentile]),\n                tuple([\"precision\", precision]),\n            ],\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_std","title":"<code>has_std(column, value)</code>","text":"<p>Validation of a column's standard deviation</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>number</code> <p>The condition for the column to match</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def has_std(self, column: str, value: float):\n    \"\"\"\n    Validation of a column's standard deviation\n\n    Args:\n        column (str): Column name in dataframe\n        value (number): The condition for the column to match\n    \"\"\"\n    Rule(\"has_std\", column, value, CheckDataType.NUMERIC) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_sum","title":"<code>has_sum(column, value)</code>","text":"<p>Validation of a sum of all values of a column</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>number</code> <p>The condition for the column to match</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def has_sum(self, column: str, value: float):\n    \"\"\"\n    Validation of a sum of all values of a column\n\n    Args:\n        column (str): Column name in dataframe\n        value (number): The condition for the column to match\n    \"\"\"\n    Rule(\"has_sum\", column, value, CheckDataType.NUMERIC) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.has_workflow","title":"<code>has_workflow(column_group, column_event, column_order, edges, pct=1.0)</code>","text":"<p>Validates events in a group clause with order, followed a specific sequence. Similar to adjacency matrix validation.</p> <p>Parameters:</p> Name Type Description Default <code>column_group</code> <code>str</code> <p>The dataframe column used to group events</p> required <code>column_event</code> <code>str</code> <p>The state of the event within the group</p> required <code>column_order</code> <code>List[date, number, str]</code> <p>The order within the group, should be deterministic and without collisions.</p> required <code>edges</code> <code>List[Tuple[str, str]]</code> <p>The combinations of events expected in the data frame i.e <code>[(\"A\",\"B\"), (\"B\",\"C\")]</code></p> required Example <p>Given the following fictitious dataset example:</p> date ticket status 2024-01-01 CASE-001 New 2024-01-02 CASE-001 In Progress 2024-01-03 CASE-001 Closed <p>You can validate that events for each ticket follow certain sequence by using:</p> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.createDataFrame(\n     [\n         [\"2024-01-01\", \"CASE-001\", \"New\"],\n         [\"2024-01-02\", \"CASE-001\", \"In Progress\"],\n         [\"2024-01-03\", \"CASE-001\", \"Closed\"],\n     ],\n     [\"date\", \"ticket\", \"status\"],\n )\n\n\ncheck = Check(CheckLevel.WARNING, \"WorkflowValidation\")\ncheck.has_workflow(\n    column_group=\"ticket\",\n    column_event=\"status\",\n    column_order=\"date\",\n    edges=[(None, \"New\"),(\"New\", \"In Progress\"),(\"In Progress\",\"Closed\"), (\"Closed\", None)]\n)\n\n# Validate\ncheck.validate(df).show(truncate=False)\n\n# Result\n+---+-------------------+------------------+-------+----------------------------+------------+------------------------------------------------------------------------------------+----+----------+---------+--------------+------+\n|id |timestamp          |check             |level  |column                      |rule        |value                                                                               |rows|violations|pass_rate|pass_threshold|status|\n+---+-------------------+------------------+-------+----------------------------+------------+------------------------------------------------------------------------------------+----+----------+---------+--------------+------+\n|1  |2024-05-11 11:24:00|WorkflowValidation|WARNING|('ticket', 'status', 'date')|has_workflow|((None, 'New'), ('New', 'In Progress'), ('In Progress', 'Closed'), ('Closed', None))|3   |0         |1.0      |1.0           |PASS  |\n+---+-------------------+------------------+-------+----------------------------+------------+------------------------------------------------------------------------------------+----+----------+---------+--------------+------+\n</code></pre> <p>The check validates that:</p> <ul> <li>Nothing preceeds a <code>New</code> state</li> <li><code>In Progress</code> follows the <code>New</code> event</li> <li><code>Closed</code> follows the <code>In Progress</code> event</li> <li>Nothing follows after <code>Closed</code> state</li> </ul> Source code in <code>cuallee/__init__.py</code> <pre><code>def has_workflow(\n    self,\n    column_group: str,\n    column_event: str,\n    column_order: str,\n    edges: List[Tuple[str]],\n    pct: float = 1.0,\n):\n    \"\"\"\n    Validates events in a group clause with order, followed a specific sequence. Similar to adjacency matrix validation.\n\n    Args:\n        column_group (str): The dataframe column used to group events\n        column_event (str): The state of the event within the group\n        column_order (List[date,number,str]): The order within the group, should be deterministic and without collisions.\n        edges (List[Tuple[str,str]]): The combinations of events expected in the data frame i.e `[(\"A\",\"B\"), (\"B\",\"C\")]`\n\n\n    ???+ example \"Example\"\n\n        Given the following fictitious dataset example:\n\n        | date       | ticket   | status      |\n        |------------|----------|-------------|\n        | 2024-01-01 | CASE-001 | New         |\n        | 2024-01-02 | CASE-001 | In Progress |\n        | 2024-01-03 | CASE-001 | Closed      |\n\n        You can validate that events for each ticket follow certain sequence by using:\n\n        ``` python\n        from cuallee import Check, CheckLevel\n        df = spark.createDataFrame(\n             [\n                 [\"2024-01-01\", \"CASE-001\", \"New\"],\n                 [\"2024-01-02\", \"CASE-001\", \"In Progress\"],\n                 [\"2024-01-03\", \"CASE-001\", \"Closed\"],\n             ],\n             [\"date\", \"ticket\", \"status\"],\n         )\n\n\n        check = Check(CheckLevel.WARNING, \"WorkflowValidation\")\n        check.has_workflow(\n            column_group=\"ticket\",\n            column_event=\"status\",\n            column_order=\"date\",\n            edges=[(None, \"New\"),(\"New\", \"In Progress\"),(\"In Progress\",\"Closed\"), (\"Closed\", None)]\n        )\n\n        # Validate\n        check.validate(df).show(truncate=False)\n\n        # Result\n        +---+-------------------+------------------+-------+----------------------------+------------+------------------------------------------------------------------------------------+----+----------+---------+--------------+------+\n        |id |timestamp          |check             |level  |column                      |rule        |value                                                                               |rows|violations|pass_rate|pass_threshold|status|\n        +---+-------------------+------------------+-------+----------------------------+------------+------------------------------------------------------------------------------------+----+----------+---------+--------------+------+\n        |1  |2024-05-11 11:24:00|WorkflowValidation|WARNING|('ticket', 'status', 'date')|has_workflow|((None, 'New'), ('New', 'In Progress'), ('In Progress', 'Closed'), ('Closed', None))|3   |0         |1.0      |1.0           |PASS  |\n        +---+-------------------+------------------+-------+----------------------------+------------+------------------------------------------------------------------------------------+----+----------+---------+--------------+------+\n\n        ```\n\n    The check validates that:\n\n    - Nothing preceeds a `New` state\n    - `In Progress` follows the `New` event\n    - `Closed` follows the `In Progress` event\n    - Nothing follows after `Closed` state\n\n    \"\"\"\n    (\n        Rule(\n            \"has_workflow\",\n            [column_group, column_event, column_order],\n            edges,\n            CheckDataType.AGNOSTIC,\n            pct,\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_between","title":"<code>is_between(column, value, pct=1.0)</code>","text":"<p>Validation of a column between a range</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>List[str, number, date]</code> <p>The condition for the column to match</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_between(self, column: str, value: Tuple[Any], pct: float = 1.0):\n    \"\"\"\n    Validation of a column between a range\n\n    Args:\n        column (str): Column name in dataframe\n        value (List[str,number,date]): The condition for the column to match\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"is_between\", column, value, CheckDataType.AGNOSTIC, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_complete","title":"<code>is_complete(column, pct=1.0)</code>","text":"<p>Validation for non-null values in column</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_complete(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validation for non-null values in column\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n\n    \"\"\"\n    Rule(\"is_complete\", column, \"N/A\", CheckDataType.AGNOSTIC, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_composite_key","title":"<code>is_composite_key(column, pct=1.0)</code>","text":"<p>Validation for unique values in a group of columns</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_composite_key(\n    self, column: Union[List[str], Tuple[str, str]], pct: float = 1.0\n):\n    \"\"\"\n    Validation for unique values in a group of columns\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    (\n        Rule(\n            \"are_unique\",\n            column,\n            \"N/A\",\n            CheckDataType.AGNOSTIC,\n            pct,\n            options={\"name\": \"is_composite_key\"},\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_contained_in","title":"<code>is_contained_in(column, value, pct=1.0, options={})</code>","text":"<p>Validation of column value in set of given values</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>List[str, number, date]</code> <p>The condition for the column to match</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_contained_in(\n    self,\n    column: str,\n    value: Union[List, Tuple],\n    pct: float = 1.0,\n    options: Dict[str, str] = {},\n):\n    \"\"\"\n    Validation of column value in set of given values\n\n    Args:\n        column (str): Column name in dataframe\n        value (List[str,number,date]): The condition for the column to match\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n\n    (\n        Rule(\n            \"is_contained_in\",\n            column,\n            value,\n            CheckDataType.AGNOSTIC,\n            pct,\n            options=options,\n        )\n        &gt;&gt; self._rule\n    )\n\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_custom","title":"<code>is_custom(column, fn=None, pct=1.0, options={})</code>","text":"<p>Uses a user-defined function that receives the to-be-validated dataframe and uses the last column of the transformed dataframe to summarize the check</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column(s) required for custom function</p> required <code>fn</code> <code>Callable</code> <p>A function that receives a dataframe as input and returns a dataframe with at least 1 column as result</p> <code>None</code> <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_custom(\n    self,\n    column: Union[str, List[str]],\n    fn: Callable = None,\n    pct: float = 1.0,\n    options: Dict[str, str] = {},\n):\n    \"\"\"\n    Uses a user-defined function that receives the to-be-validated dataframe\n    and uses the last column of the transformed dataframe to summarize the check\n\n    Args:\n        column (str): Column(s) required for custom function\n        fn (Callable): A function that receives a dataframe as input and returns a dataframe with at least 1 column as result\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n\n    (\n        Rule(\"is_custom\", column, fn, CheckDataType.AGNOSTIC, pct, options=options)\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_daily","title":"<code>is_daily(column, value=None, pct=1.0)</code>","text":"<p>Validates that there is no missing dates using only week days in the date/timestamp column.</p> <p>An alternative day combination can be provided given that a user wants to validate only certain dates. For example in PySpark to validate that time series are every Wednesday consecutively on a year without any missing values, the value input should contain <code>[4]</code> as it represent the numeric equivalence of the day of week Wednesday.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>value</code> <code>List[int]</code> <p>A list of numbers describing the days of the week to consider. i.e. Pyspark uses [2, 3, 4, 5, 6] for Mon-Fri</p> <code>None</code> <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_daily(\n    self, column: str, value: Union[None, List[int]] = None, pct: float = 1.0\n):\n    \"\"\"\n    Validates that there is no missing dates using only week days in the date/timestamp column.\n\n    An alternative day combination can be provided given that a user wants to validate only certain dates.\n    For example in PySpark to validate that time series are every Wednesday consecutively on a year\n    without any missing values, the value input should contain `[4]` as it represent the numeric\n    equivalence of the day of week Wednesday.\n\n    Args:\n        column (str): Column name in the dataframe\n        value (List[int]): A list of numbers describing the days of the week to consider. i.e. Pyspark uses [2, 3, 4, 5, 6] for Mon-Fri\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    (Rule(\"is_daily\", column, value, CheckDataType.DATE, pct) &gt;&gt; self._rule)\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_empty","title":"<code>is_empty(column, pct=1.0)</code>","text":"<p>Validation for null values in column</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_empty(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validation for null values in column\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n\n    \"\"\"\n    Rule(\"is_empty\", column, \"N/A\", CheckDataType.AGNOSTIC, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_equal_than","title":"<code>is_equal_than(column, value, pct=1.0)</code>","text":"<p>Validation for numeric column equal than value</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>number</code> <p>The condition for the column to match</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_equal_than(self, column: str, value: float, pct: float = 1.0):\n    \"\"\"\n    Validation for numeric column equal than value\n\n    Args:\n        column (str): Column name in dataframe\n        value (number): The condition for the column to match\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"is_equal_than\", column, value, CheckDataType.NUMERIC, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_greater_or_equal_than","title":"<code>is_greater_or_equal_than(column, value, pct=1.0)</code>","text":"<p>Validation for numeric greater or equal than value</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>number</code> <p>The condition for the column to match</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_greater_or_equal_than(self, column: str, value: float, pct: float = 1.0):\n    \"\"\"\n    Validation for numeric greater or equal than value\n\n    Args:\n        column (str): Column name in dataframe\n        value (number): The condition for the column to match\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    (\n        Rule(\"is_greater_or_equal_than\", column, value, CheckDataType.NUMERIC, pct)\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_greater_than","title":"<code>is_greater_than(column, value, pct=1.0)</code>","text":"<p>Validation for numeric greater than value</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>number</code> <p>The condition for the column to match</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_greater_than(self, column: str, value: float, pct: float = 1.0):\n    \"\"\"\n    Validation for numeric greater than value\n\n    Args:\n        column (str): Column name in dataframe\n        value (number): The condition for the column to match\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"is_greater_than\", column, value, CheckDataType.NUMERIC, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_in","title":"<code>is_in(column, value, pct=1.0)</code>","text":"<p>Vaildation of column value in set of given values</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>List[str, number, date]</code> <p>The condition for the column to match</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_in(self, column: str, value: Tuple[str, int, float], pct: float = 1.0):\n    \"\"\"\n    Vaildation of column value in set of given values\n\n    Args:\n        column (str): Column name in dataframe\n        value (List[str,number,date]): The condition for the column to match\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    return self.is_contained_in(column, value, pct, options={\"name\": \"is_in\"})\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_in_billions","title":"<code>is_in_billions(column, pct=1.0)</code>","text":"<p>Validates that a column has values greater than 1B (1e9)</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_in_billions(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validates that a column has values greater than 1B (1e9)\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    return self.is_greater_or_equal_than(column, 1e9, pct)\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_in_millions","title":"<code>is_in_millions(column, pct=1.0)</code>","text":"<p>Validates that a column has values greater than 1M (1e6)</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_in_millions(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validates that a column has values greater than 1M (1e6)\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    return self.is_greater_or_equal_than(column, 1e6, pct)\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_inside_interquartile_range","title":"<code>is_inside_interquartile_range(column, value=[0.25, 0.75], pct=1.0)</code>","text":"<p>Validates a number resides inside the quartile(1) and quartile(3) of the range of values</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>List[number]</code> <p>A number between 0 and 1 demarking the quartile</p> <code>[0.25, 0.75]</code> <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_inside_interquartile_range(\n    self, column: str, value: List[float] = [0.25, 0.75], pct: float = 1.0\n):\n    \"\"\"\n    Validates a number resides inside the quartile(1) and quartile(3) of the range of values\n\n    Args:\n        column (str): Column name in dataframe\n        value (List[number]): A number between 0 and 1 demarking the quartile\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    (\n        Rule(\n            \"is_inside_interquartile_range\",\n            column,\n            value,\n            CheckDataType.NUMERIC,\n            pct,\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_legit","title":"<code>is_legit(column, pct=1.0)</code>","text":"<p>Validation for string columns giving wrong signal about completeness due to empty strings.</p> <p>Useful for reading CSV files and preventing empty strings being reported as valid records. This is an <code>alias</code> implementation of the <code>has_pattern</code> rule using <code>not black space</code> as the pattern Which validates the presence of non-empty characters between the begining and end of a string.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_legit(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validation for string columns giving wrong signal about completeness due to empty strings.\n\n    Useful for reading CSV files and preventing empty strings being reported as valid records.\n    This is an `alias` implementation of the `has_pattern` rule using `not black space` as the pattern\n    Which validates the presence of non-empty characters between the begining and end of a string.\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    (\n        Rule(\n            \"has_pattern\",\n            column,\n            r\"^\\S+$\",\n            CheckDataType.STRING,\n            pct,\n            options={\"name\": \"is_legit\"},\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_less_or_equal_than","title":"<code>is_less_or_equal_than(column, value, pct=1.0)</code>","text":"<p>Validation for numeric less or equal than value</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>number</code> <p>The condition for the column to match</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_less_or_equal_than(self, column: str, value: float, pct: float = 1.0):\n    \"\"\"\n    Validation for numeric less or equal than value\n\n    Args:\n        column (str): Column name in dataframe\n        value (number): The condition for the column to match\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    (\n        Rule(\"is_less_or_equal_than\", column, value, CheckDataType.NUMERIC, pct)\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_less_than","title":"<code>is_less_than(column, value, pct=1.0)</code>","text":"<p>Validation for numeric less than value</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>number</code> <p>The condition for the column to match</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_less_than(self, column: str, value: float, pct: float = 1.0):\n    \"\"\"\n    Validation for numeric less than value\n\n    Args:\n        column (str): Column name in dataframe\n        value (number): The condition for the column to match\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"is_less_than\", column, value, CheckDataType.NUMERIC, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_negative","title":"<code>is_negative(column, pct=1.0)</code>","text":"<p>Validation for numeric less than zero</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_negative(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validation for numeric less than zero\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    return self.is_less_than(column, 0, pct)\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_on_friday","title":"<code>is_on_friday(column, pct=1.0)</code>","text":"<p>Validates a datetime column is on Friday</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_on_friday(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validates a datetime column is on Friday\n\n    Args:\n        column (str): Column name in the dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"is_on_friday\", column, \"Fri\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_on_monday","title":"<code>is_on_monday(column, pct=1.0)</code>","text":"<p>Validates a datetime column is on Monday</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_on_monday(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validates a datetime column is on Monday\n\n    Args:\n        column (str): Column name in the dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"is_on_monday\", column, \"Mon\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_on_saturday","title":"<code>is_on_saturday(column, pct=1.0)</code>","text":"<p>Validates a datetime column is on Saturday</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_on_saturday(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validates a datetime column is on Saturday\n\n    Args:\n        column (str): Column name in the dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"is_on_saturday\", column, \"Sat\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_on_schedule","title":"<code>is_on_schedule(column, value, pct=1.0)</code>","text":"<p>Validation of a datetime column between an hour interval</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>value</code> <code>Tuple[int, int]</code> <p>A tuple indicating a 24hr day interval. i.e. (9,17) for 9am to 5pm</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_on_schedule(self, column: str, value: Tuple[Any], pct: float = 1.0):\n    \"\"\"\n    Validation of a datetime column between an hour interval\n\n    Args:\n        column (str): Column name in the dataframe\n        value (Tuple[int,int]): A tuple indicating a 24hr day interval. i.e. (9,17) for 9am to 5pm\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    (\n        Rule(\"is_on_schedule\", column, value, CheckDataType.TIMESTAMP, pct)\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_on_sunday","title":"<code>is_on_sunday(column, pct=1.0)</code>","text":"<p>Validates a datetime column is on Sunday</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_on_sunday(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validates a datetime column is on Sunday\n\n    Args:\n        column (str): Column name in the dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"is_on_sunday\", column, \"Sun\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_on_thursday","title":"<code>is_on_thursday(column, pct=1.0)</code>","text":"<p>Validates a datetime column is on Thursday</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_on_thursday(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validates a datetime column is on Thursday\n\n    Args:\n        column (str): Column name in the dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"is_on_thursday\", column, \"Thu\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_on_tuesday","title":"<code>is_on_tuesday(column, pct=1.0)</code>","text":"<p>Validates a datetime column is on Tuesday</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_on_tuesday(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validates a datetime column is on Tuesday\n\n    Args:\n        column (str): Column name in the dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"is_on_tuesday\", column, \"Tue\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_on_wednesday","title":"<code>is_on_wednesday(column, pct=1.0)</code>","text":"<p>Validates a datetime column is on Wednesday</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_on_wednesday(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validates a datetime column is on Wednesday\n\n    Args:\n        column (str): Column name in the dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"is_on_wednesday\", column, \"Wed\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_on_weekday","title":"<code>is_on_weekday(column, pct=1.0)</code>","text":"<p>Validates a datetime column is in a Mon-Fri time range</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_on_weekday(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validates a datetime column is in a Mon-Fri time range\n\n    Args:\n        column (str): Column name in the dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"is_on_weekday\", column, \"Mon-Fri\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_on_weekend","title":"<code>is_on_weekend(column, pct=1.0)</code>","text":"<p>Validates a datetime column is in a Sat-Sun time range</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_on_weekend(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validates a datetime column is in a Sat-Sun time range\n\n    Args:\n        column (str): Column name in the dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    Rule(\"is_on_weekend\", column, \"Sat-Sun\", CheckDataType.DATE, pct) &gt;&gt; self._rule\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_positive","title":"<code>is_positive(column, pct=1.0)</code>","text":"<p>Validation for numeric greater than zero</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_positive(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validation for numeric greater than zero\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    return self.is_greater_than(column, 0, pct)\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_primary_key","title":"<code>is_primary_key(column, pct=1.0)</code>","text":"<p>Validation for unique values in column</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_primary_key(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validation for unique values in column\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    (\n        Rule(\n            \"is_unique\",\n            column,\n            \"N/A\",\n            CheckDataType.AGNOSTIC,\n            pct,\n            options={\"name\": \"is_primary_key\"},\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_t_minus_1","title":"<code>is_t_minus_1(column, pct=1.0)</code>","text":"<p>Validate that date is yesterday</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_t_minus_1(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validate that date is yesterday\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    return self.is_t_minus_n(column, 1, pct, options={\"name\": \"is_t_minus_1\"})\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_t_minus_2","title":"<code>is_t_minus_2(column, pct=1.0)</code>","text":"<p>Validate that date is 2 days ago</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_t_minus_2(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validate that date is 2 days ago\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    return self.is_t_minus_n(column, 2, pct, options={\"name\": \"is_t_minus_2\"})\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_t_minus_3","title":"<code>is_t_minus_3(column, pct=1.0)</code>","text":"<p>Validate that date is 3 days ago</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_t_minus_3(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validate that date is 3 days ago\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    return self.is_t_minus_n(column, 3, pct, options={\"name\": \"is_t_minus_3\"})\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_t_minus_n","title":"<code>is_t_minus_n(column, value, pct=1.0, options={'name': 'is_t_minus_n'})</code>","text":"<p>Validate that date is <code>n</code> days before the current date</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>List[str, number, date]</code> <p>The number of days before the current date</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_t_minus_n(\n    self,\n    column: str,\n    value: int,\n    pct: float = 1.0,\n    options: Dict[str, str] = {\"name\": \"is_t_minus_n\"},\n):\n    \"\"\"\n    Validate that date is `n` days before the current date\n\n    Args:\n        column (str): Column name in dataframe\n        value (List[str,number,date]): The number of days before the current date\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    yesterday = datetime.utcnow() - timedelta(days=value)\n    return self.is_contained_in(\n        column, tuple([yesterday.strftime(\"%Y-%m-%d\")]), pct, options=options\n    )\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_today","title":"<code>is_today(column, pct=1.0)</code>","text":"<p>Validate that date is today</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_today(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validate that date is today\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    return self.is_t_minus_n(column, 0, pct, options={\"name\": \"is_today\"})\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_unique","title":"<code>is_unique(column, pct=1.0, approximate=False, ignore_nulls=False)</code>","text":"<p>Validation for unique values in column</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> <code>approximate</code> <code>bool</code> <p>A flag to speed up computation using an approximation through maximum relative std. dev.</p> <code>False</code> <code>ignore_nulls</code> <code>bool</code> <p>Run drop nulls before counting</p> <code>False</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_unique(\n    self,\n    column: str,\n    pct: float = 1.0,\n    approximate: bool = False,\n    ignore_nulls: bool = False,\n):\n    \"\"\"\n    Validation for unique values in column\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n        approximate (bool): A flag to speed up computation using an approximation through maximum relative std. dev.\n        ignore_nulls (bool): Run drop nulls before counting\n    \"\"\"\n    (\n        Rule(\n            \"is_unique\",\n            column,\n            \"N/A\",\n            CheckDataType.AGNOSTIC,\n            pct,\n            options={\"approximate\": approximate, \"ignore_nulls\": ignore_nulls},\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.is_yesterday","title":"<code>is_yesterday(column, pct=1.0)</code>","text":"<p>Validate that date is yesterday</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def is_yesterday(self, column: str, pct: float = 1.0):\n    \"\"\"\n    Validate that date is yesterday\n\n    Args:\n        column (str): Column name in dataframe\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    return self.is_t_minus_n(column, 1, pct, options={\"name\": \"is_yesterday\"})\n</code></pre>"},{"location":"module/check/#cuallee.Check.not_contained_in","title":"<code>not_contained_in(column, value, pct=1.0)</code>","text":"<p>Validation of column value not in set of given values</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>List[str, number, date]</code> <p>The condition for the column to match</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def not_contained_in(\n    self,\n    column: str,\n    value: Union[List, Tuple],\n    pct: float = 1.0,\n):\n    \"\"\"\n    Validation of column value not in set of given values\n\n    Args:\n        column (str): Column name in dataframe\n        value (List[str,number,date]): The condition for the column to match\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    (\n        Rule(\"not_contained_in\", column, value, CheckDataType.AGNOSTIC, pct)\n        &gt;&gt; self._rule\n    )\n\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.not_in","title":"<code>not_in(column, value, pct=1.0)</code>","text":"<p>Validation of column value not in set of given values</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in dataframe</p> required <code>value</code> <code>List[str, number, date]</code> <p>The condition for the column to match</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def not_in(self, column: str, value: Tuple[str, int, float], pct: float = 1.0):\n    \"\"\"\n    Validation of column value not in set of given values\n\n    Args:\n        column (str): Column name in dataframe\n        value (List[str,number,date]): The condition for the column to match\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    return self.not_contained_in(column, value, pct)\n</code></pre>"},{"location":"module/check/#cuallee.Check.ok","title":"<code>ok(dataframe)</code>","text":"<p>True when all checks passed</p> Source code in <code>cuallee/__init__.py</code> <pre><code>def ok(self, dataframe: Any) -&gt; bool:\n    \"\"\"True when all checks passed\"\"\"\n    return self.validate(dataframe, ok=True)\n</code></pre>"},{"location":"module/check/#cuallee.Check.satisfies","title":"<code>satisfies(column, predicate, pct=1.0, options={})</code>","text":"<p>Validation of a column satisfying a SQL-like predicate</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name in the dataframe</p> required <code>predicate</code> <code>str</code> <p>A predicate written in SQL-like syntax</p> required <code>pct</code> <code>float</code> <p>The threshold percentage required to pass</p> <code>1.0</code> Source code in <code>cuallee/__init__.py</code> <pre><code>def satisfies(\n    self,\n    column: str,\n    predicate: str,\n    pct: float = 1.0,\n    options: Dict[str, str] = {},\n):\n    \"\"\"\n    Validation of a column satisfying a SQL-like predicate\n\n    Args:\n        column (str): Column name in the dataframe\n        predicate (str): A predicate written in SQL-like syntax\n        pct (float): The threshold percentage required to pass\n    \"\"\"\n    (\n        Rule(\n            \"satisfies\",\n            column,\n            predicate,\n            CheckDataType.AGNOSTIC,\n            pct,\n            options=options,\n        )\n        &gt;&gt; self._rule\n    )\n    return self\n</code></pre>"},{"location":"module/check/#cuallee.Check.validate","title":"<code>validate(dataframe, ok=False)</code>","text":"<p>Compute all rules in this check for specific data frame</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>Union[pyspark, snowpark, pandas, polars, duckdb, bigquery]</code> <p>A dataframe object</p> required Source code in <code>cuallee/__init__.py</code> <pre><code>def validate(self, dataframe: Any, ok: bool = False):\n    \"\"\"\n    Compute all rules in this check for specific data frame\n\n    Args:\n        dataframe (Union[pyspark,snowpark,pandas,polars,duckdb,bigquery]): A dataframe object\n    \"\"\"\n\n    # Stop execution if the there is no rules in the check\n    assert not self.empty, \"Check is empty. Try adding some rules?\"\n\n    self.dtype = first(re.match(r\".*'(.*)'\", str(type(dataframe))).groups())\n    match self.dtype:\n        case self.dtype if \"pyspark\" in self.dtype:\n            self.compute_engine = importlib.import_module(\n                \"cuallee.pyspark_validation\"\n            )\n        case self.dtype if \"pandas\" in self.dtype:\n            self.compute_engine = importlib.import_module(\n                \"cuallee.pandas_validation\"\n            )\n        case self.dtype if \"snowpark\" in self.dtype:\n            self.compute_engine = importlib.import_module(\n                \"cuallee.snowpark_validation\"\n            )\n        case self.dtype if \"polars\" in self.dtype:\n            self.compute_engine = importlib.import_module(\n                \"cuallee.polars_validation\"\n            )\n        case self.dtype if \"duckdb\" in self.dtype:\n            self.compute_engine = importlib.import_module(\n                \"cuallee.duckdb_validation\"\n            )\n        case self.dtype if \"bigquery\" in self.dtype:\n            self.compute_engine = importlib.import_module(\n                \"cuallee.bigquery_validation\"\n            )\n        case self.dtype if \"daft\" in self.dtype:\n            self.compute_engine = importlib.import_module(\"cuallee.daft_validation\")\n        case _:\n            raise NotImplementedError(\n                f\"{self.dtype} is not yet implemented in cuallee\"\n            )\n\n    assert self.compute_engine.validate_data_types(\n        self.rules, dataframe\n    ), \"Invalid data types between rules and dataframe\"\n\n    if ok:\n        result = self.compute_engine.ok(self, dataframe)\n    else:\n        result = self.compute_engine.summary(self, dataframe)\n    return result\n</code></pre>"},{"location":"module/rule/","title":"Rule","text":"<p>Predicate definition holder</p> Source code in <code>cuallee/__init__.py</code> <pre><code>@dataclass\nclass Rule:\n    \"\"\"Predicate definition holder\"\"\"\n\n    method: str\n    column: Union[str, List[str], Tuple[str, str]]\n    value: Optional[Any]\n    data_type: CheckDataType\n    coverage: float = 1.0\n    options: Union[List[Tuple], None] = None\n    status: Union[str, None] = None\n    violations: int = 0\n    pass_rate: float = 0.0\n    ordinal: int = 0\n    name: str = None\n\n    @property\n    def settings(self) -&gt; dict:\n        \"\"\"holds the additional settings for the predicate execution\"\"\"\n        return dict(self.options)\n\n    @property\n    def key(self):\n        \"\"\"blake2s hash of the rule, made of method, column, value, options and coverage\"\"\"\n        return (\n            hashlib.blake2s(\n                bytes(\n                    f\"{self.method}{self.column}{self.value}{self.options}{self.coverage}\",\n                    \"utf-8\",\n                )\n            )\n            .hexdigest()\n            .upper()\n        )\n\n    def __post_init__(self):\n        if (self.coverage &lt;= 0) or (self.coverage &gt; 1):\n            raise ValueError(\"Coverage should be between 0 and 1\")\n\n        if isinstance(self.column, List):\n            self.column = tuple(self.column)\n\n        if isinstance(self.value, List):\n            self.value = tuple(self.value)\n\n        if isinstance(self.value, Tuple) &amp; (self.data_type == CheckDataType.AGNOSTIC):\n            # All values can only be of one data type in a rule\n            if len(Counter(map(type, self.value)).keys()) &gt; 1:\n                raise ValueError(\"Data types in rule values are inconsistent\")\n\n        if (\n            self.options\n            and isinstance(self.options, dict)\n            and (rule_name := self.options.get(\"name\"))\n        ):\n            self.name = rule_name\n        else:\n            self.name = self.method\n\n    def __repr__(self):\n        return f\"Rule(method:{self.name}, column:{self.column}, value:{self.value}, data_type:{self.data_type}, coverage:{self.coverage}, ordinal:{self.ordinal}\"\n\n    def __rshift__(self, rule_dict: Dict[str, Any]) -&gt; Dict[str, Any]:\n        rule_dict[self.key] = self\n        return rule_dict\n\n    def evaluate_violations(self, result: Any, rows: int):\n        \"\"\"Calculates the row violations on the rule\"\"\"\n\n        if isinstance(result, str):\n            if result == \"false\":\n                self.violations = rows\n            elif result == \"true\":\n                self.violations = 0\n            else:\n                self.violations = abs(int(result))\n        elif isinstance(result, bool):\n            if result is True:\n                self.violations = 0\n            elif result is False:\n                self.violations = rows\n        elif isinstance(result, int):\n            if result == 0:\n                self.violations = rows\n            elif result &lt; 0:\n                self.violations = abs(result)\n            elif (result &gt; 0) and (result &lt; rows):\n                self.violations = rows - result\n\n        else:\n            self.violations = 0\n\n    def evaluate_pass_rate(self, rows: int):\n        \"\"\"Percentage of successful rows by this rule\"\"\"\n        if self.violations &lt;= rows:\n            try:\n                self.pass_rate = 1 - (self.violations / rows)\n            except ZeroDivisionError:\n                self.pass_rate = 1.0\n        else:\n            try:\n                self.pass_rate = rows / self.violations\n            except ZeroDivisionError:\n                self.pass_rate = 0.0\n\n    def evaluate_status(self):\n        \"\"\"Overall PASS/FAIL status of the rule\"\"\"\n        if self.pass_rate &gt;= self.coverage:\n            self.status = \"PASS\"\n        else:\n            self.status = \"FAIL\"\n\n    def evaluate(self, result: Any, rows: int):\n        \"\"\"Generic rule evaluation for checks\"\"\"\n        self.evaluate_violations(result, rows)\n        self.evaluate_pass_rate(rows)\n        self.evaluate_status()\n</code></pre>"},{"location":"module/rule/#cuallee.Rule.key","title":"<code>key</code>  <code>property</code>","text":"<p>blake2s hash of the rule, made of method, column, value, options and coverage</p>"},{"location":"module/rule/#cuallee.Rule.settings","title":"<code>settings</code>  <code>property</code>","text":"<p>holds the additional settings for the predicate execution</p>"},{"location":"module/rule/#cuallee.Rule.evaluate","title":"<code>evaluate(result, rows)</code>","text":"<p>Generic rule evaluation for checks</p> Source code in <code>cuallee/__init__.py</code> <pre><code>def evaluate(self, result: Any, rows: int):\n    \"\"\"Generic rule evaluation for checks\"\"\"\n    self.evaluate_violations(result, rows)\n    self.evaluate_pass_rate(rows)\n    self.evaluate_status()\n</code></pre>"},{"location":"module/rule/#cuallee.Rule.evaluate_pass_rate","title":"<code>evaluate_pass_rate(rows)</code>","text":"<p>Percentage of successful rows by this rule</p> Source code in <code>cuallee/__init__.py</code> <pre><code>def evaluate_pass_rate(self, rows: int):\n    \"\"\"Percentage of successful rows by this rule\"\"\"\n    if self.violations &lt;= rows:\n        try:\n            self.pass_rate = 1 - (self.violations / rows)\n        except ZeroDivisionError:\n            self.pass_rate = 1.0\n    else:\n        try:\n            self.pass_rate = rows / self.violations\n        except ZeroDivisionError:\n            self.pass_rate = 0.0\n</code></pre>"},{"location":"module/rule/#cuallee.Rule.evaluate_status","title":"<code>evaluate_status()</code>","text":"<p>Overall PASS/FAIL status of the rule</p> Source code in <code>cuallee/__init__.py</code> <pre><code>def evaluate_status(self):\n    \"\"\"Overall PASS/FAIL status of the rule\"\"\"\n    if self.pass_rate &gt;= self.coverage:\n        self.status = \"PASS\"\n    else:\n        self.status = \"FAIL\"\n</code></pre>"},{"location":"module/rule/#cuallee.Rule.evaluate_violations","title":"<code>evaluate_violations(result, rows)</code>","text":"<p>Calculates the row violations on the rule</p> Source code in <code>cuallee/__init__.py</code> <pre><code>def evaluate_violations(self, result: Any, rows: int):\n    \"\"\"Calculates the row violations on the rule\"\"\"\n\n    if isinstance(result, str):\n        if result == \"false\":\n            self.violations = rows\n        elif result == \"true\":\n            self.violations = 0\n        else:\n            self.violations = abs(int(result))\n    elif isinstance(result, bool):\n        if result is True:\n            self.violations = 0\n        elif result is False:\n            self.violations = rows\n    elif isinstance(result, int):\n        if result == 0:\n            self.violations = rows\n        elif result &lt; 0:\n            self.violations = abs(result)\n        elif (result &gt; 0) and (result &lt; rows):\n            self.violations = rows - result\n\n    else:\n        self.violations = 0\n</code></pre>"},{"location":"pandas/","title":"Pandas","text":"<p>In order to follow this examples, make sure your installation is all set for <code>pandas</code></p> <p>Install</p> <pre><code>pip install cuallee\npip install cuallee[pandas]\n</code></pre>"},{"location":"pandas/#is_complete","title":"is_complete","text":"<p>It validates the completeness attribute of a data set. It confirms that a column does not contain <code>null</code> values.</p> is_complete  PASS FAIL THRESHOLD <p>In this example, we validate that the column <code>id</code> does not have any missing values.</p> <pre><code>import pandas as pd\nfrom cuallee import Check\n\ndf = pd.DataFrame({\"id\" : [1,2,3,4,5]})\ncheck = Check()\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(df)\n</code></pre> <p> output:</p> <pre><code>id            timestamp          check    level column         rule value  rows  violations  pass_rate  pass_threshold status\n 1  2024-05-18 16:22:53  cuallee.check  WARNING     id  is_complete   N/A     5           0        1.0             1.0   PASS\n</code></pre> <p>In this example, we intentionally place 2 <code>null</code> values in the dataframe and that produces a <code>FAIL</code> check as result.</p> <pre><code>import pandas as pd\nfrom cuallee import Check\n\ndf = pd.DataFrame({\"id\" : [1,2,3,None, None]})\ncheck = Check()\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(df)\n</code></pre> <p> output:</p> <pre><code>id            timestamp          check    level column         rule value  rows  violations  pass_rate  pass_threshold status\n 1  2024-05-18 16:33:55  cuallee.check  WARNING     id  is_complete   N/A     5           2        0.6             1.0   FAIL\n</code></pre> <p>In this example, we validate reuse the data frame with empty values from the previous example, however we set our tolerance via the <code>pct</code> parameter on the rule <code>is_complete</code> to <code>0.6</code>. Producing now a <code>PASS</code> result on the check, regardless of the <code>2</code> present <code>null</code> values.</p> <pre><code>import pandas as pd\nfrom cuallee import Check\n\ndf = pd.DataFrame({\"id\" : [1,2,3,None, None]})\ncheck = Check()\ncheck.is_complete(\"id\", pct=0.6)\n\n# Validate\ncheck.validate(df)\n</code></pre> <p> output:</p> <pre><code>id            timestamp          check    level column         rule value  rows  violations  pass_rate  pass_threshold status\n 1  2024-05-18 16:33:55  cuallee.check  WARNING     id  is_complete   N/A     5           2        0.6             0.6   PASS\n</code></pre>"},{"location":"polars/","title":"Polars","text":"<p>In order to follow this examples, make sure your installation is all set for <code>polars</code></p> <p>Install</p> <pre><code>pip install cuallee\npip install cuallee[polars]\n</code></pre>"},{"location":"polars/#is_complete","title":"is_complete","text":"<p>It validates the completeness attribute of a data set. It confirms that a column does not contain <code>null</code> values   .</p> is_complete  PASS FAIL THRESHOLD <p>In this example, we validate that the column <code>id</code> does not have any missing values.</p> <pre><code>import polars as pl\nfrom cuallee import Check\n\ndf = pl.DataFrame({\"id\" : [1,2,3,4,5]})\ncheck = Check()\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(df)\n</code></pre> <p> output:</p> <pre><code>shape: (1, 12)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 id  \u2506 timestamp           \u2506 check         \u2506 level   \u2506 column \u2506 rule        \u2506 value \u2506 rows \u2506 violations \u2506 pass_rate \u2506 pass_threshold \u2506 status \u2502\n\u2502 --- \u2506 ---                 \u2506 ---           \u2506 ---     \u2506 ---    \u2506 ---         \u2506 ---   \u2506 ---  \u2506 ---        \u2506 ---       \u2506 ---            \u2506 ---    \u2502\n\u2502 i64 \u2506 str                 \u2506 str           \u2506 str     \u2506 str    \u2506 str         \u2506 str   \u2506 i64  \u2506 i64        \u2506 f64       \u2506 f64            \u2506 str    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 2024-05-18 16:53:56 \u2506 cuallee.check \u2506 WARNING \u2506 id     \u2506 is_complete \u2506 N/A   \u2506 5    \u2506 0          \u2506 1.0       \u2506 1.0            \u2506 PASS   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>In this example, we intentionally place 2 <code>null</code> values in the dataframe and that produces a <code>FAIL</code> check as result.</p> <pre><code>import polars as pl\nfrom cuallee import Check\n\ndf = pl.DataFrame({\"id\" : [1,2,3,None, None]})\ncheck = Check()\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(df)\n</code></pre> <p> output:</p> <pre><code>shape: (1, 12)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 id  \u2506 timestamp           \u2506 check         \u2506 level   \u2506 column \u2506 rule        \u2506 value \u2506 rows \u2506 violations \u2506 pass_rate \u2506 pass_threshold \u2506 status \u2502\n\u2502 --- \u2506 ---                 \u2506 ---           \u2506 ---     \u2506 ---    \u2506 ---         \u2506 ---   \u2506 ---  \u2506 ---        \u2506 ---       \u2506 ---            \u2506 ---    \u2502\n\u2502 i64 \u2506 str                 \u2506 str           \u2506 str     \u2506 str    \u2506 str         \u2506 str   \u2506 i64  \u2506 i64        \u2506 f64       \u2506 f64            \u2506 str    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 2024-05-18 16:53:56 \u2506 cuallee.check \u2506 WARNING \u2506 id     \u2506 is_complete \u2506 N/A   \u2506 5    \u2506 2          \u2506 0.6       \u2506 1.0            \u2506 FAIL   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>In this example, we validate reuse the data frame with empty values from the previous example, however we set our tolerance via the <code>pct</code> parameter on the rule <code>is_complete</code> to <code>0.6</code>. Producing now a <code>PASS</code> result on the check, regardless of the <code>2</code> present <code>null</code> values.</p> <pre><code>import polars as pl\nfrom cuallee import Check\n\ndf = pl.DataFrame({\"id\" : [1,2,3,None, None]})\ncheck = Check()\ncheck.is_complete(\"id\", pct=0.6)\n\n# Validate\ncheck.validate(df)\n</code></pre> <p> output:</p> <pre><code>shape: (1, 12)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 id  \u2506 timestamp           \u2506 check         \u2506 level   \u2506 column \u2506 rule        \u2506 value \u2506 rows \u2506 violations \u2506 pass_rate \u2506 pass_threshold \u2506 status \u2502\n\u2502 --- \u2506 ---                 \u2506 ---           \u2506 ---     \u2506 ---    \u2506 ---         \u2506 ---   \u2506 ---  \u2506 ---        \u2506 ---       \u2506 ---            \u2506 ---    \u2502\n\u2502 i64 \u2506 str                 \u2506 str           \u2506 str     \u2506 str    \u2506 str         \u2506 str   \u2506 i64  \u2506 i64        \u2506 f64       \u2506 f64            \u2506 str    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 2024-05-18 16:53:56 \u2506 cuallee.check \u2506 WARNING \u2506 id     \u2506 is_complete \u2506 N/A   \u2506 5    \u2506 2          \u2506 0.6       \u2506 0.6            \u2506 PASS   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"pyspark/","title":"PySpark","text":"<p>In order to follow this examples, make sure your installation is all set for <code>pyspark</code></p> <p>Install</p> <pre><code>pip install cuallee\npip install cuallee[pyspark]\n</code></pre>"},{"location":"pyspark/#is_complete","title":"is_complete","text":"<p>It validates the completeness attribute of a data set. It confirms that a column does not contain <code>null</code> values.</p> is_complete  PASS FAIL THRESHOLD <p>In this example, we validate that the column <code>id</code> does not have any missing values.</p> <pre><code>from pyspark.sql import SparkSession\nfrom cuallee import Check\n\nspark = SparkSession.builder.getOrCreate()\ndf = spark.range(10)\ncheck = Check()\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(df).show()\n</code></pre> <p> output:</p> <pre><code>+---+-------------------+-------------+-------+------+-----------+-----+----+----------+---------+--------------+------+\n| id|          timestamp|        check|  level|column|       rule|value|rows|violations|pass_rate|pass_threshold|status|\n+---+-------------------+-------------+-------+------+-----------+-----+----+----------+---------+--------------+------+\n|  1|2024-05-18 16:53:56|cuallee.check|WARNING|    id|is_complete|  N/A|  10|         0|      1.0|           1.0|  PASS|\n+---+-------------------+-------------+-------+------+-----------+-----+----+----------+---------+--------------+------+\n</code></pre> <p>In this example, we intentionally place 2 <code>null</code> values in the dataframe and that produces a <code>FAIL</code> check as result.</p> <pre><code>from pyspark.sql import SparkSession\nfrom cuallee import Check\n\nspark = SparkSession.builder.getOrCreate()\ndf = spark.range(8).union(spark.createDataFrame([(None,), (None,)], schema=\"id int\"))\ncheck = Check()\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(df).show()\n</code></pre> <p> output:</p> <pre><code>+---+-------------------+-------------+-------+------+-----------+-----+----+----------+---------+--------------+------+\n| id|          timestamp|        check|  level|column|       rule|value|rows|violations|pass_rate|pass_threshold|status|\n+---+-------------------+-------------+-------+------+-----------+-----+----+----------+---------+--------------+------+\n|  1|2024-05-18 16:53:56|cuallee.check|WARNING|    id|is_complete|  N/A|  10|         2|      0.8|           1.0|  FAIL|\n+---+-------------------+-------------+-------+------+-----------+-----+----+----------+---------+--------------+------+\n</code></pre> <p>In this example, we validate reuse the data frame with empty values from the previous example, however we set our tolerance via the <code>pct</code> parameter on the rule <code>is_complete</code> to <code>0.8</code>. Producing now a <code>PASS</code> result on the check, regardless of the <code>2</code> present <code>null</code> values.</p> <pre><code>from pyspark.sql import SparkSession\nfrom cuallee import Check\n\nspark = SparkSession.builder.getOrCreate()\ndf = spark.range(8).union(spark.createDataFrame([(None,), (None,)], schema=\"id int\"))\ncheck = Check()\ncheck.is_complete(\"id\", pct=0.8)\n\n# Validate\ncheck.validate(df).show()\n</code></pre> <p> output:</p> <pre><code>+---+-------------------+-------------+-------+------+-----------+-----+----+----------+---------+--------------+------+\n| id|          timestamp|        check|  level|column|       rule|value|rows|violations|pass_rate|pass_threshold|status|\n+---+-------------------+-------------+-------+------+-----------+-----+----+----------+---------+--------------+------+\n|  1|2024-05-18 16:53:56|cuallee.check|WARNING|    id|is_complete|  N/A|  10|         2|      0.8|           0.8|  PASS|\n+---+-------------------+-------------+-------+------+-----------+-----+----+----------+---------+--------------+------+\n</code></pre>"},{"location":"snowpark/","title":"Snowpark","text":"<p>In order to follow this examples, make sure your installation is all set for <code>snowpark</code></p> <p>Install</p> <pre><code>pip install cuallee\npip install cuallee[snowpark]\n</code></pre>"},{"location":"snowpark/#pre-requisites","title":"Pre-Requisites","text":"<p>You will have a SnowFlake account in order to proceed with the examples below. Once you get an account, you can obtain your account details normally located in the bottom left corner of your SnowFlake environment. The following environment variables are required and used during runtime from <code>cuallee</code> to connect to your instance:</p> <ul> <li><code>SF_ACCOUNT</code>=<code>hp00000.us-east4.gcp</code></li> <li><code>SF_USER</code>=<code>user.name@cuallee.com</code></li> <li><code>SF_PASSWORD</code>=<code>MySecretPa$$word?</code></li> <li><code>SF_ROLE</code>=<code>ACCOUNTADMIN</code></li> <li><code>SF_WAREHOUSE</code>=<code>COMPUTE_WH</code></li> <li><code>SF_DATABASE</code>=<code>SNOWFLAKE_SAMPLE_DATA</code></li> <li><code>SF_SCHEMA</code>=<code>TPCH_SF10</code></li> </ul> <p>Cost Associated</p> <p>Be aware that running <code>cuallee</code> checks in <code>snowpark</code> incurs into cloud costs.</p>"},{"location":"snowpark/#in-snowflake","title":"In SnowFlake","text":"<p>The following How-To guide, explains the steps to configure <code>cuallee</code> directly in SnowFlake:</p> <p>SnowFlake Data Quality Setup</p>"},{"location":"snowpark/#is_complete","title":"is_complete","text":"<p>It validates the completeness attribute of a data set. It confirms that a column does not contain <code>null</code> values.</p> is_complete  PASS FAIL THRESHOLD <p>In this example, we validate that the column <code>id</code> does not have any missing values.</p> <pre><code>import os\nfrom snowflake.snowpark import Session\nfrom cuallee import Check\n\nsettings = {\n    \"account\": os.getenv(\"SF_ACCOUNT\"),\n    \"user\": os.getenv(\"SF_USER\"),\n    \"password\": os.getenv(\"SF_PASSWORD\"),\n    \"role\": os.getenv(\"SF_ROLE\"),\n    \"warehouse\": os.getenv(\"SF_WAREHOUSE\"),\n    \"database\": os.getenv(\"SF_DATABASE\"),\n    \"schema\": os.getenv(\"SF_SCHEMA\"),\n}\n\nsnowpark = Session.builder.configs(settings).create()\ndf = snowpark.range(10)\ncheck = Check()\ncheck.is_complete(\"ID\")\n\n# Validate\ncheck.validate(df).show()\n</code></pre> <p> output:</p> <pre><code>---------------------------------------------------------------------------------------------------------------------------------------------------------------\n|\"ID\"  |\"TIMESTAMP\"          |\"CHECK\"        |\"LEVEL\"  |\"COLUMN\"  |\"RULE\"       |\"VALUE\"  |\"ROWS\"  |\"VIOLATIONS\"  |\"PASS_RATE\"  |\"PASS_THRESHOLD\"  |\"STATUS\"  |\n---------------------------------------------------------------------------------------------------------------------------------------------------------------\n|1     |2024-05-18 20:47:28  |cuallee.check  |WARNING  |ID        |is_complete  |N/A      |10      |0.0           |1.0          |1.0               |PASS      |\n---------------------------------------------------------------------------------------------------------------------------------------------------------------\n</code></pre> <p>In this example, we intentionally place 2 <code>null</code> values in the dataframe and that produces a <code>FAIL</code> check as result.</p> <pre><code>import os\nfrom snowflake.snowpark import Session\nfrom cuallee import Check\n\nsettings = {\n    \"account\": os.getenv(\"SF_ACCOUNT\"),\n    \"user\": os.getenv(\"SF_USER\"),\n    \"password\": os.getenv(\"SF_PASSWORD\"),\n    \"role\": os.getenv(\"SF_ROLE\"),\n    \"warehouse\": os.getenv(\"SF_WAREHOUSE\"),\n    \"database\": os.getenv(\"SF_DATABASE\"),\n    \"schema\": os.getenv(\"SF_SCHEMA\"),\n}\n\nsnowpark = Session.builder.configs(settings).create()\ndf = snowpark.range(8).union_all(snowpark.create_dataframe([[None], [None]], [\"ID\"]))\ncheck = Check()\ncheck.is_complete(\"ID\")\n\n# Validate\ncheck.validate(df).show()\n</code></pre> <p> output:</p> <pre><code>---------------------------------------------------------------------------------------------------------------------------------------------------------------\n|\"ID\"  |\"TIMESTAMP\"          |\"CHECK\"        |\"LEVEL\"  |\"COLUMN\"  |\"RULE\"       |\"VALUE\"  |\"ROWS\"  |\"VIOLATIONS\"  |\"PASS_RATE\"  |\"PASS_THRESHOLD\"  |\"STATUS\"  |\n---------------------------------------------------------------------------------------------------------------------------------------------------------------\n|1     |2024-05-18 20:47:28  |cuallee.check  |WARNING  |ID        |is_complete  |N/A      |10      |2.0           |0.8          |1.0               |FAIL      |\n---------------------------------------------------------------------------------------------------------------------------------------------------------------\n</code></pre> <p>In this example, we validate reuse the data frame with empty values from the previous example, however we set our tolerance via the <code>pct</code> parameter on the rule <code>is_complete</code> to <code>0.8</code>. Producing now a <code>PASS</code> result on the check, regardless of the <code>2</code> present <code>null</code> values.</p> <pre><code>import os\nfrom snowflake.snowpark import Session\nfrom cuallee import Check\n\nsettings = {\n    \"account\": os.getenv(\"SF_ACCOUNT\"),\n    \"user\": os.getenv(\"SF_USER\"),\n    \"password\": os.getenv(\"SF_PASSWORD\"),\n    \"role\": os.getenv(\"SF_ROLE\"),\n    \"warehouse\": os.getenv(\"SF_WAREHOUSE\"),\n    \"database\": os.getenv(\"SF_DATABASE\"),\n    \"schema\": os.getenv(\"SF_SCHEMA\"),\n}\n\nsnowpark = Session.builder.configs(settings).create()\ndf = snowpark.range(8).union_all(snowpark.create_dataframe([[None], [None]], [\"ID\"]))\ncheck = Check()\ncheck.is_complete(\"ID\", pct=0.8)\n\n# Validate\ncheck.validate(df).show()\n</code></pre> <p> output:</p> <pre><code>---------------------------------------------------------------------------------------------------------------------------------------------------------------\n|\"ID\"  |\"TIMESTAMP\"          |\"CHECK\"        |\"LEVEL\"  |\"COLUMN\"  |\"RULE\"       |\"VALUE\"  |\"ROWS\"  |\"VIOLATIONS\"  |\"PASS_RATE\"  |\"PASS_THRESHOLD\"  |\"STATUS\"  |\n---------------------------------------------------------------------------------------------------------------------------------------------------------------\n|1     |2024-05-18 20:47:28  |cuallee.check  |WARNING  |ID        |is_complete  |N/A      |10      |2.0           |0.8          |0.8               |PASS      |\n---------------------------------------------------------------------------------------------------------------------------------------------------------------\n</code></pre>"}]}